{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d8a9e5",
   "metadata": {},
   "source": [
    "# Setup enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79a0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading in Dataframe format and data preprocessing\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Linear algebra operations\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning models and preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "\n",
    "# Epiweek\n",
    "from epiweeks import Week, Year\n",
    "\n",
    "# Date\n",
    "from datetime import date as convert_to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3682c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8cfe734",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = 'Embeddings/embeddings_vae_1024features.csv'\n",
    "labels = 'Tabular_data/Label_CSV_All_Municipality.csv'\n",
    "MUNICIPALITY = 'Medellín'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3af1cc8",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af24bdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epiweek_from_date(image_date):\n",
    "    date = image_date.split('-')\n",
    "    \n",
    "    # Get year as int\n",
    "    year = ''.join(filter(str.isdigit, date[0]))\n",
    "    year = int(year)\n",
    "    \n",
    "    # Get month as int\n",
    "    month = ''.join(filter(str.isdigit, date[1]))\n",
    "    month = int(month)\n",
    "    \n",
    "    # Get day as int\n",
    "    day = ''.join(filter(str.isdigit, date[2]))\n",
    "    day = int(day)\n",
    "    \n",
    "    # Get epiweek:\n",
    "    date = convert_to_date(year, month, day)\n",
    "    epiweek = str(Week.fromdate(date))\n",
    "    epiweek = int(epiweek)\n",
    "    \n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3454fce",
   "metadata": {},
   "source": [
    "### 1. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e029ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_features(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    #df.Date = pd.to_datetime(df.Date)\n",
    "    \n",
    "    if Municipality:\n",
    "        print('Obtaining dataframe for the city of Medellin only...')\n",
    "        df = df[df['Municipality Code'] == Municipality]\n",
    "        \n",
    "    df.Date = df.Date.apply(epiweek_from_date)\n",
    "    \n",
    "    df = df.sort_values(by=['Date'])\n",
    "    \n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    if Municipality:\n",
    "        df.drop(columns=['Municipality Code'], inplace=True)\n",
    "        \n",
    "    df.index.name = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "352f1e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining dataframe for the city of Medellin only...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201544</th>\n",
       "      <td>-0.046489</td>\n",
       "      <td>-1.407201</td>\n",
       "      <td>-1.148883</td>\n",
       "      <td>0.836687</td>\n",
       "      <td>-0.190778</td>\n",
       "      <td>1.802231</td>\n",
       "      <td>0.517497</td>\n",
       "      <td>-1.146697</td>\n",
       "      <td>0.119171</td>\n",
       "      <td>1.544828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678144</td>\n",
       "      <td>-0.036498</td>\n",
       "      <td>-0.303533</td>\n",
       "      <td>0.248490</td>\n",
       "      <td>-0.811357</td>\n",
       "      <td>-0.832925</td>\n",
       "      <td>-0.739305</td>\n",
       "      <td>-0.295200</td>\n",
       "      <td>-0.038603</td>\n",
       "      <td>0.485674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201545</th>\n",
       "      <td>0.327904</td>\n",
       "      <td>-0.701594</td>\n",
       "      <td>0.306197</td>\n",
       "      <td>-0.796750</td>\n",
       "      <td>-1.037395</td>\n",
       "      <td>0.857556</td>\n",
       "      <td>0.167456</td>\n",
       "      <td>1.642044</td>\n",
       "      <td>-0.473234</td>\n",
       "      <td>0.181270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897844</td>\n",
       "      <td>-0.661285</td>\n",
       "      <td>-1.146673</td>\n",
       "      <td>-1.234707</td>\n",
       "      <td>-0.184185</td>\n",
       "      <td>-0.140669</td>\n",
       "      <td>-2.367193</td>\n",
       "      <td>-0.463623</td>\n",
       "      <td>-0.668936</td>\n",
       "      <td>-0.233073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201546</th>\n",
       "      <td>-1.634988</td>\n",
       "      <td>-0.882196</td>\n",
       "      <td>0.291420</td>\n",
       "      <td>-2.686286</td>\n",
       "      <td>-0.684004</td>\n",
       "      <td>-0.407912</td>\n",
       "      <td>1.827255</td>\n",
       "      <td>0.327352</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906685</td>\n",
       "      <td>1.372330</td>\n",
       "      <td>-0.333867</td>\n",
       "      <td>0.728862</td>\n",
       "      <td>-0.005498</td>\n",
       "      <td>-0.743434</td>\n",
       "      <td>0.597319</td>\n",
       "      <td>0.195301</td>\n",
       "      <td>-0.850010</td>\n",
       "      <td>0.492581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201547</th>\n",
       "      <td>1.789035</td>\n",
       "      <td>0.854698</td>\n",
       "      <td>-2.904163</td>\n",
       "      <td>-1.008464</td>\n",
       "      <td>-0.165688</td>\n",
       "      <td>0.597984</td>\n",
       "      <td>0.142369</td>\n",
       "      <td>0.164123</td>\n",
       "      <td>1.069377</td>\n",
       "      <td>0.236612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254610</td>\n",
       "      <td>-0.536157</td>\n",
       "      <td>-0.424962</td>\n",
       "      <td>0.685125</td>\n",
       "      <td>-0.029501</td>\n",
       "      <td>0.095485</td>\n",
       "      <td>0.379560</td>\n",
       "      <td>-0.297148</td>\n",
       "      <td>-1.211405</td>\n",
       "      <td>0.443391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201548</th>\n",
       "      <td>-0.983180</td>\n",
       "      <td>0.145126</td>\n",
       "      <td>0.720849</td>\n",
       "      <td>1.524544</td>\n",
       "      <td>0.620878</td>\n",
       "      <td>-1.807810</td>\n",
       "      <td>0.340521</td>\n",
       "      <td>0.781281</td>\n",
       "      <td>-0.395229</td>\n",
       "      <td>-0.769379</td>\n",
       "      <td>...</td>\n",
       "      <td>1.562922</td>\n",
       "      <td>0.585608</td>\n",
       "      <td>-0.675990</td>\n",
       "      <td>0.232964</td>\n",
       "      <td>0.788353</td>\n",
       "      <td>0.147064</td>\n",
       "      <td>0.094748</td>\n",
       "      <td>-0.206415</td>\n",
       "      <td>1.170020</td>\n",
       "      <td>0.276934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>-0.177821</td>\n",
       "      <td>0.800357</td>\n",
       "      <td>0.158949</td>\n",
       "      <td>2.573438</td>\n",
       "      <td>1.615337</td>\n",
       "      <td>-0.998008</td>\n",
       "      <td>1.096824</td>\n",
       "      <td>-0.023870</td>\n",
       "      <td>-0.667530</td>\n",
       "      <td>-1.929526</td>\n",
       "      <td>...</td>\n",
       "      <td>2.209477</td>\n",
       "      <td>0.241274</td>\n",
       "      <td>-1.311355</td>\n",
       "      <td>0.955204</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.715542</td>\n",
       "      <td>-0.870650</td>\n",
       "      <td>-0.205803</td>\n",
       "      <td>0.835786</td>\n",
       "      <td>1.692061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>-0.306444</td>\n",
       "      <td>1.308680</td>\n",
       "      <td>1.067536</td>\n",
       "      <td>-0.931025</td>\n",
       "      <td>-1.046062</td>\n",
       "      <td>2.075529</td>\n",
       "      <td>-0.501223</td>\n",
       "      <td>-2.267342</td>\n",
       "      <td>0.095569</td>\n",
       "      <td>-0.845871</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.447275</td>\n",
       "      <td>0.293684</td>\n",
       "      <td>-1.791375</td>\n",
       "      <td>-0.086890</td>\n",
       "      <td>0.917567</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>-2.004170</td>\n",
       "      <td>0.267849</td>\n",
       "      <td>1.151415</td>\n",
       "      <td>-1.051147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>-0.151392</td>\n",
       "      <td>0.071449</td>\n",
       "      <td>0.356428</td>\n",
       "      <td>0.259774</td>\n",
       "      <td>-0.383608</td>\n",
       "      <td>1.065443</td>\n",
       "      <td>0.450759</td>\n",
       "      <td>0.322183</td>\n",
       "      <td>-1.307717</td>\n",
       "      <td>-0.181305</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033319</td>\n",
       "      <td>0.951084</td>\n",
       "      <td>0.638319</td>\n",
       "      <td>-0.277678</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>-0.329121</td>\n",
       "      <td>-0.322632</td>\n",
       "      <td>-1.898407</td>\n",
       "      <td>-0.602611</td>\n",
       "      <td>-0.267056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>-0.793142</td>\n",
       "      <td>-0.539722</td>\n",
       "      <td>-1.165816</td>\n",
       "      <td>-0.199017</td>\n",
       "      <td>2.244849</td>\n",
       "      <td>0.917043</td>\n",
       "      <td>-0.467799</td>\n",
       "      <td>0.353362</td>\n",
       "      <td>1.053764</td>\n",
       "      <td>0.443968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882802</td>\n",
       "      <td>-0.827243</td>\n",
       "      <td>-0.127070</td>\n",
       "      <td>-1.308614</td>\n",
       "      <td>-1.632518</td>\n",
       "      <td>1.059085</td>\n",
       "      <td>1.047949</td>\n",
       "      <td>-2.762428</td>\n",
       "      <td>-0.955669</td>\n",
       "      <td>0.913588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>-0.393870</td>\n",
       "      <td>1.455486</td>\n",
       "      <td>-0.128889</td>\n",
       "      <td>-0.788440</td>\n",
       "      <td>0.381879</td>\n",
       "      <td>0.022924</td>\n",
       "      <td>0.543938</td>\n",
       "      <td>-0.070586</td>\n",
       "      <td>-0.623824</td>\n",
       "      <td>-0.382842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705277</td>\n",
       "      <td>0.204254</td>\n",
       "      <td>-0.124967</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0.031512</td>\n",
       "      <td>2.580178</td>\n",
       "      <td>-0.813275</td>\n",
       "      <td>-0.418657</td>\n",
       "      <td>-0.572518</td>\n",
       "      <td>-0.936024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201544 -0.046489 -1.407201 -1.148883  0.836687 -0.190778  1.802231  0.517497   \n",
       "201545  0.327904 -0.701594  0.306197 -0.796750 -1.037395  0.857556  0.167456   \n",
       "201546 -1.634988 -0.882196  0.291420 -2.686286 -0.684004 -0.407912  1.827255   \n",
       "201547  1.789035  0.854698 -2.904163 -1.008464 -0.165688  0.597984  0.142369   \n",
       "201548 -0.983180  0.145126  0.720849  1.524544  0.620878 -1.807810  0.340521   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "201848 -0.177821  0.800357  0.158949  2.573438  1.615337 -0.998008  1.096824   \n",
       "201849 -0.306444  1.308680  1.067536 -0.931025 -1.046062  2.075529 -0.501223   \n",
       "201850 -0.151392  0.071449  0.356428  0.259774 -0.383608  1.065443  0.450759   \n",
       "201851 -0.793142 -0.539722 -1.165816 -0.199017  2.244849  0.917043 -0.467799   \n",
       "201852 -0.393870  1.455486 -0.128889 -0.788440  0.381879  0.022924  0.543938   \n",
       "\n",
       "               7         8         9  ...      1014      1015      1016  \\\n",
       "201544 -1.146697  0.119171  1.544828  ... -0.678144 -0.036498 -0.303533   \n",
       "201545  1.642044 -0.473234  0.181270  ... -0.897844 -0.661285 -1.146673   \n",
       "201546  0.327352  0.987357  0.781570  ...  0.906685  1.372330 -0.333867   \n",
       "201547  0.164123  1.069377  0.236612  ...  0.254610 -0.536157 -0.424962   \n",
       "201548  0.781281 -0.395229 -0.769379  ...  1.562922  0.585608 -0.675990   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "201848 -0.023870 -0.667530 -1.929526  ...  2.209477  0.241274 -1.311355   \n",
       "201849 -2.267342  0.095569 -0.845871  ... -2.447275  0.293684 -1.791375   \n",
       "201850  0.322183 -1.307717 -0.181305  ...  1.033319  0.951084  0.638319   \n",
       "201851  0.353362  1.053764  0.443968  ...  0.882802 -0.827243 -0.127070   \n",
       "201852 -0.070586 -0.623824 -0.382842  ...  0.705277  0.204254 -0.124967   \n",
       "\n",
       "            1017      1018      1019      1020      1021      1022      1023  \n",
       "201544  0.248490 -0.811357 -0.832925 -0.739305 -0.295200 -0.038603  0.485674  \n",
       "201545 -1.234707 -0.184185 -0.140669 -2.367193 -0.463623 -0.668936 -0.233073  \n",
       "201546  0.728862 -0.005498 -0.743434  0.597319  0.195301 -0.850010  0.492581  \n",
       "201547  0.685125 -0.029501  0.095485  0.379560 -0.297148 -1.211405  0.443391  \n",
       "201548  0.232964  0.788353  0.147064  0.094748 -0.206415  1.170020  0.276934  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "201848  0.955204  0.006918  0.715542 -0.870650 -0.205803  0.835786  1.692061  \n",
       "201849 -0.086890  0.917567  0.631528 -2.004170  0.267849  1.151415 -1.051147  \n",
       "201850 -0.277678  0.032450 -0.329121 -0.322632 -1.898407 -0.602611 -0.267056  \n",
       "201851 -1.308614 -1.632518  1.059085  1.047949 -2.762428 -0.955669  0.913588  \n",
       "201852  0.008888  0.031512  2.580178 -0.813275 -0.418657 -0.572518 -0.936024  \n",
       "\n",
       "[165 rows x 1024 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = read_features(path=embeddings, Municipality=MUNICIPALITY)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38360ac2",
   "metadata": {},
   "source": [
    "### 2. Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "808df552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epiweek(name):\n",
    "    \n",
    "    # Get week\n",
    "    week = name.split('/')[1]\n",
    "    week = week.replace('w','')\n",
    "    week = int(week)\n",
    "    \n",
    "    # Year\n",
    "    year = name.split('/')[0]\n",
    "    year = int(year)\n",
    "    \n",
    "    epiweek = Week(year, week)\n",
    "    \n",
    "    epiweek = str(epiweek)\n",
    "    epiweek = int(epiweek)\n",
    "\n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b73f0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    if df.shape[1] > 678:\n",
    "        df = pd.concat([df[['Municipality code', 'Municipality']], df.iloc[:,-676:]], axis=1)\n",
    "        cols = df.iloc[:, 2:].columns\n",
    "        new_cols = df.iloc[:, 2:].columns.to_series().apply(get_epiweek)\n",
    "        df = df.rename(columns=dict(zip(cols, new_cols))) \n",
    "        \n",
    "    if 'Label_CSV_All_Municipality' in path:\n",
    "        # Get Columns\n",
    "        df = df[['epiweek', 'Municipality code', 'Municipality', 'final_cases_label']]\n",
    "        \n",
    "        # change epiweek format\n",
    "        df.epiweek = df.epiweek.apply(get_epiweek)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        df = df[df.duplicated(['epiweek','Municipality code','Municipality']) == False]\n",
    "        \n",
    "        # Replace Increase, decrease, stable to numerical:\n",
    "        \"\"\"\n",
    "        - Stable = 0\n",
    "        - Increased = 1 \n",
    "        - Decreased = 2\n",
    "        \"\"\"\n",
    "        df.final_cases_label = df.final_cases_label.replace({'Stable': 0, 'Increased': 1, 'Decreased': 2})\n",
    "        \n",
    "        # Create table\n",
    "        df = df.pivot(index=['Municipality code', 'Municipality'], columns='epiweek', values='final_cases_label')\n",
    "\n",
    "        # Reset Index:\n",
    "        df = df.reset_index()\n",
    "    \n",
    "    if Municipality:\n",
    "        df = df[df['Municipality'] == Municipality]\n",
    "        df.drop(columns=['Municipality code'], inplace=True)\n",
    "        df.rename(columns={'Municipality': 'Municipality Code'}, inplace=True)\n",
    "    \n",
    "        df = df.set_index('Municipality Code')\n",
    "        df = df.T\n",
    "\n",
    "        df.columns.name = None\n",
    "        df.index.name = None\n",
    "        \n",
    "        df.columns = ['Labels']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "027560a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1  2\n",
       "201601  1  0  0\n",
       "201602  0  1  0\n",
       "201603  0  0  1\n",
       "201604  1  0  0\n",
       "201605  1  0  0\n",
       "...    .. .. ..\n",
       "201848  1  0  0\n",
       "201849  0  0  1\n",
       "201850  0  1  0\n",
       "201851  1  0  0\n",
       "201852  1  0  0\n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = read_labels(path=labels, Municipality=MUNICIPALITY)\n",
    "labels_df_orig = labels_df\n",
    "labels_df = pd.get_dummies(labels_df['Labels'])\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8831d1",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "586d07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = labels_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59d7bdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>1.287487</td>\n",
       "      <td>-0.688955</td>\n",
       "      <td>-0.794426</td>\n",
       "      <td>-1.238838</td>\n",
       "      <td>1.239369</td>\n",
       "      <td>1.784700</td>\n",
       "      <td>-0.000341</td>\n",
       "      <td>0.525795</td>\n",
       "      <td>0.363034</td>\n",
       "      <td>0.825218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.439056</td>\n",
       "      <td>0.675143</td>\n",
       "      <td>-1.017167</td>\n",
       "      <td>-0.206480</td>\n",
       "      <td>-0.043412</td>\n",
       "      <td>-1.014832</td>\n",
       "      <td>-1.435265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>-1.399851</td>\n",
       "      <td>-0.211775</td>\n",
       "      <td>1.341302</td>\n",
       "      <td>0.132593</td>\n",
       "      <td>-0.097550</td>\n",
       "      <td>0.159015</td>\n",
       "      <td>-1.474547</td>\n",
       "      <td>-1.294940</td>\n",
       "      <td>1.222341</td>\n",
       "      <td>-0.381582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.420181</td>\n",
       "      <td>-1.341189</td>\n",
       "      <td>-0.138499</td>\n",
       "      <td>-1.804684</td>\n",
       "      <td>-0.662659</td>\n",
       "      <td>0.475712</td>\n",
       "      <td>0.201907</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>-0.405975</td>\n",
       "      <td>0.289439</td>\n",
       "      <td>-0.377020</td>\n",
       "      <td>-0.355364</td>\n",
       "      <td>-1.054876</td>\n",
       "      <td>0.712196</td>\n",
       "      <td>0.927682</td>\n",
       "      <td>-0.470455</td>\n",
       "      <td>-0.252064</td>\n",
       "      <td>1.062808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587504</td>\n",
       "      <td>0.340662</td>\n",
       "      <td>0.299123</td>\n",
       "      <td>0.405674</td>\n",
       "      <td>-2.638784</td>\n",
       "      <td>0.780803</td>\n",
       "      <td>-1.659373</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0.844463</td>\n",
       "      <td>-1.315463</td>\n",
       "      <td>2.082394</td>\n",
       "      <td>2.693551</td>\n",
       "      <td>-1.234441</td>\n",
       "      <td>1.570999</td>\n",
       "      <td>0.279815</td>\n",
       "      <td>0.831815</td>\n",
       "      <td>-0.229177</td>\n",
       "      <td>-0.052932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959280</td>\n",
       "      <td>-0.753616</td>\n",
       "      <td>1.713913</td>\n",
       "      <td>1.536158</td>\n",
       "      <td>-1.955070</td>\n",
       "      <td>0.051035</td>\n",
       "      <td>-1.663397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>-0.541275</td>\n",
       "      <td>0.475828</td>\n",
       "      <td>0.136089</td>\n",
       "      <td>0.335247</td>\n",
       "      <td>1.387429</td>\n",
       "      <td>0.863202</td>\n",
       "      <td>-1.643587</td>\n",
       "      <td>-0.673929</td>\n",
       "      <td>-0.331307</td>\n",
       "      <td>-1.289601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362812</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>-0.509349</td>\n",
       "      <td>0.104454</td>\n",
       "      <td>-3.172053</td>\n",
       "      <td>0.055130</td>\n",
       "      <td>0.444714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>-0.177821</td>\n",
       "      <td>0.800357</td>\n",
       "      <td>0.158949</td>\n",
       "      <td>2.573438</td>\n",
       "      <td>1.615337</td>\n",
       "      <td>-0.998008</td>\n",
       "      <td>1.096824</td>\n",
       "      <td>-0.023870</td>\n",
       "      <td>-0.667530</td>\n",
       "      <td>-1.929526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955204</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.715542</td>\n",
       "      <td>-0.870650</td>\n",
       "      <td>-0.205803</td>\n",
       "      <td>0.835786</td>\n",
       "      <td>1.692061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>-0.306444</td>\n",
       "      <td>1.308680</td>\n",
       "      <td>1.067536</td>\n",
       "      <td>-0.931025</td>\n",
       "      <td>-1.046062</td>\n",
       "      <td>2.075529</td>\n",
       "      <td>-0.501223</td>\n",
       "      <td>-2.267342</td>\n",
       "      <td>0.095569</td>\n",
       "      <td>-0.845871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086890</td>\n",
       "      <td>0.917567</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>-2.004170</td>\n",
       "      <td>0.267849</td>\n",
       "      <td>1.151415</td>\n",
       "      <td>-1.051147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>-0.151392</td>\n",
       "      <td>0.071449</td>\n",
       "      <td>0.356428</td>\n",
       "      <td>0.259774</td>\n",
       "      <td>-0.383608</td>\n",
       "      <td>1.065443</td>\n",
       "      <td>0.450759</td>\n",
       "      <td>0.322183</td>\n",
       "      <td>-1.307717</td>\n",
       "      <td>-0.181305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277678</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>-0.329121</td>\n",
       "      <td>-0.322632</td>\n",
       "      <td>-1.898407</td>\n",
       "      <td>-0.602611</td>\n",
       "      <td>-0.267056</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>-0.793142</td>\n",
       "      <td>-0.539722</td>\n",
       "      <td>-1.165816</td>\n",
       "      <td>-0.199017</td>\n",
       "      <td>2.244849</td>\n",
       "      <td>0.917043</td>\n",
       "      <td>-0.467799</td>\n",
       "      <td>0.353362</td>\n",
       "      <td>1.053764</td>\n",
       "      <td>0.443968</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.308614</td>\n",
       "      <td>-1.632518</td>\n",
       "      <td>1.059085</td>\n",
       "      <td>1.047949</td>\n",
       "      <td>-2.762428</td>\n",
       "      <td>-0.955669</td>\n",
       "      <td>0.913588</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>-0.393870</td>\n",
       "      <td>1.455486</td>\n",
       "      <td>-0.128889</td>\n",
       "      <td>-0.788440</td>\n",
       "      <td>0.381879</td>\n",
       "      <td>0.022924</td>\n",
       "      <td>0.543938</td>\n",
       "      <td>-0.070586</td>\n",
       "      <td>-0.623824</td>\n",
       "      <td>-0.382842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0.031512</td>\n",
       "      <td>2.580178</td>\n",
       "      <td>-0.813275</td>\n",
       "      <td>-0.418657</td>\n",
       "      <td>-0.572518</td>\n",
       "      <td>-0.936024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201601  1.287487 -0.688955 -0.794426 -1.238838  1.239369  1.784700 -0.000341   \n",
       "201602 -1.399851 -0.211775  1.341302  0.132593 -0.097550  0.159015 -1.474547   \n",
       "201603 -0.405975  0.289439 -0.377020 -0.355364 -1.054876  0.712196  0.927682   \n",
       "201604  0.844463 -1.315463  2.082394  2.693551 -1.234441  1.570999  0.279815   \n",
       "201605 -0.541275  0.475828  0.136089  0.335247  1.387429  0.863202 -1.643587   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "201848 -0.177821  0.800357  0.158949  2.573438  1.615337 -0.998008  1.096824   \n",
       "201849 -0.306444  1.308680  1.067536 -0.931025 -1.046062  2.075529 -0.501223   \n",
       "201850 -0.151392  0.071449  0.356428  0.259774 -0.383608  1.065443  0.450759   \n",
       "201851 -0.793142 -0.539722 -1.165816 -0.199017  2.244849  0.917043 -0.467799   \n",
       "201852 -0.393870  1.455486 -0.128889 -0.788440  0.381879  0.022924  0.543938   \n",
       "\n",
       "               7         8         9  ...      1017      1018      1019  \\\n",
       "201601  0.525795  0.363034  0.825218  ... -0.439056  0.675143 -1.017167   \n",
       "201602 -1.294940  1.222341 -0.381582  ... -0.420181 -1.341189 -0.138499   \n",
       "201603 -0.470455 -0.252064  1.062808  ... -0.587504  0.340662  0.299123   \n",
       "201604  0.831815 -0.229177 -0.052932  ...  0.959280 -0.753616  1.713913   \n",
       "201605 -0.673929 -0.331307 -1.289601  ... -0.362812 -0.104197 -0.509349   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "201848 -0.023870 -0.667530 -1.929526  ...  0.955204  0.006918  0.715542   \n",
       "201849 -2.267342  0.095569 -0.845871  ... -0.086890  0.917567  0.631528   \n",
       "201850  0.322183 -1.307717 -0.181305  ... -0.277678  0.032450 -0.329121   \n",
       "201851  0.353362  1.053764  0.443968  ... -1.308614 -1.632518  1.059085   \n",
       "201852 -0.070586 -0.623824 -0.382842  ...  0.008888  0.031512  2.580178   \n",
       "\n",
       "            1020      1021      1022      1023  0  1  2  \n",
       "201601 -0.206480 -0.043412 -1.014832 -1.435265  1  0  0  \n",
       "201602 -1.804684 -0.662659  0.475712  0.201907  0  1  0  \n",
       "201603  0.405674 -2.638784  0.780803 -1.659373  0  0  1  \n",
       "201604  1.536158 -1.955070  0.051035 -1.663397  1  0  0  \n",
       "201605  0.104454 -3.172053  0.055130  0.444714  1  0  0  \n",
       "...          ...       ...       ...       ... .. .. ..  \n",
       "201848 -0.870650 -0.205803  0.835786  1.692061  1  0  0  \n",
       "201849 -2.004170  0.267849  1.151415 -1.051147  0  0  1  \n",
       "201850 -0.322632 -1.898407 -0.602611 -0.267056  0  1  0  \n",
       "201851  1.047949 -2.762428 -0.955669  0.913588  1  0  0  \n",
       "201852 -0.813275 -0.418657 -0.572518 -0.936024  1  0  0  \n",
       "\n",
       "[156 rows x 1027 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes based on the date values\n",
    "dengue_df = features_df.merge(labels_df, how='inner', left_index=True, right_index=True)\n",
    "dengue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0c03a0",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83983da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_percentage = 80):\n",
    "    # We need a sequence so we can't split randomly\n",
    "    # To divide into Train and test we have to calculate the train percentage of the dataset:\n",
    "    size = df.shape[0]\n",
    "    split = int(size*(train_percentage/100))\n",
    "    \n",
    "    \"\"\" Train \"\"\"\n",
    "    # We will train with 1st percentage % of data and test with the rest\n",
    "    train_df = df.iloc[:split,:] ## percentage % train\n",
    "    \n",
    "    \"\"\" Test \"\"\"\n",
    "    test_df = df.iloc[split:,:] # 100 - percentage % test\n",
    "    \n",
    "    print(f'The train shape is: {train_df.shape}')\n",
    "    print(f'The test shape is: {test_df.shape}')\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6401830b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train shape is: (124, 1027)\n",
      "The test shape is: (32, 1027)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(dengue_df, train_percentage = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7d9ab0",
   "metadata": {},
   "source": [
    "### Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe12c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train data and create the scaler\n",
    "def normalize_train_features(df, feature_range=(-1, 1), n_labels=None):\n",
    "    \n",
    "    if n_labels:\n",
    "        n_features = df.shape[1] - n_labels\n",
    "    \n",
    "    scalers = {}\n",
    "    # For each column in the dataframe\n",
    "    for i, column in enumerate(df.columns):\n",
    "        if n_labels:\n",
    "            if i >= n_features:\n",
    "                break\n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Generate a new scaler\n",
    "        scaler = MinMaxScaler(feature_range=feature_range)\n",
    "        # Fit the scaler just for that column\n",
    "        scaled_column = scaler.fit_transform(values)\n",
    "        # Add the scaled column to the dataframe\n",
    "        scaled_column = np.reshape(scaled_column, len(scaled_column))\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "        # Save the scaler of the column\n",
    "        scalers['scaler_' + column] = scaler\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df, scalers\n",
    "\n",
    "\n",
    "\"\"\" If you want to use the same scaler used in train, you can use this function\"\"\"\n",
    "def normalize_test_features(df, scalers=None, n_labels=None):\n",
    "    \n",
    "    if not scalers:\n",
    "        raise TypeError(\"You should provide a list of scalers.\")\n",
    "    \n",
    "    if n_labels:\n",
    "        n_features = df.shape[1] - n_labels\n",
    "    \n",
    "    for i, column in enumerate(df.columns):\n",
    "        if n_labels:\n",
    "            if i >= n_features:\n",
    "                break\n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Take the scaler of that column\n",
    "        scaler = scalers['scaler_' + column]\n",
    "        # Scale values\n",
    "        scaled_column = scaler.transform(values)\n",
    "        scaled_column = np.reshape(scaled_column,len(scaled_column))\n",
    "        # Add the scaled values to the df\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "364232d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "0      -1.0\n",
      "1      -1.0\n",
      "2      -1.0\n",
      "3      -1.0\n",
      "4      -1.0\n",
      "       ... \n",
      "1022   -1.0\n",
      "1023   -1.0\n",
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "Length: 1027, dtype: float64\n",
      " Max values are: \n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "1022    1.0\n",
      "1023    1.0\n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "Length: 1027, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>0.717415</td>\n",
       "      <td>-0.264619</td>\n",
       "      <td>-0.512345</td>\n",
       "      <td>-0.596061</td>\n",
       "      <td>0.474445</td>\n",
       "      <td>0.534150</td>\n",
       "      <td>-0.046372</td>\n",
       "      <td>-0.033960</td>\n",
       "      <td>0.317819</td>\n",
       "      <td>0.237751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131012</td>\n",
       "      <td>0.127058</td>\n",
       "      <td>-0.319972</td>\n",
       "      <td>0.037591</td>\n",
       "      <td>0.106643</td>\n",
       "      <td>-0.352494</td>\n",
       "      <td>-0.615821</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>-0.419614</td>\n",
       "      <td>-0.077807</td>\n",
       "      <td>0.419405</td>\n",
       "      <td>-0.042335</td>\n",
       "      <td>0.008382</td>\n",
       "      <td>-0.073435</td>\n",
       "      <td>-0.675073</td>\n",
       "      <td>-0.723629</td>\n",
       "      <td>0.606674</td>\n",
       "      <td>-0.262004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122372</td>\n",
       "      <td>-0.760683</td>\n",
       "      <td>-0.018953</td>\n",
       "      <td>-0.522950</td>\n",
       "      <td>-0.092673</td>\n",
       "      <td>0.164985</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.118415</td>\n",
       "      <td>-0.330244</td>\n",
       "      <td>-0.239351</td>\n",
       "      <td>-0.325351</td>\n",
       "      <td>0.133311</td>\n",
       "      <td>0.349401</td>\n",
       "      <td>-0.411326</td>\n",
       "      <td>0.111055</td>\n",
       "      <td>0.336141</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198964</td>\n",
       "      <td>-0.020205</td>\n",
       "      <td>0.130970</td>\n",
       "      <td>0.252293</td>\n",
       "      <td>-0.728723</td>\n",
       "      <td>0.270905</td>\n",
       "      <td>-0.716005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0.529969</td>\n",
       "      <td>-0.509892</td>\n",
       "      <td>0.742719</td>\n",
       "      <td>0.991672</td>\n",
       "      <td>-0.387949</td>\n",
       "      <td>0.454282</td>\n",
       "      <td>0.073106</td>\n",
       "      <td>0.081956</td>\n",
       "      <td>0.118748</td>\n",
       "      <td>-0.125905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509073</td>\n",
       "      <td>-0.501989</td>\n",
       "      <td>0.615657</td>\n",
       "      <td>0.648789</td>\n",
       "      <td>-0.508657</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>-0.717804</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>-0.056345</td>\n",
       "      <td>0.191385</td>\n",
       "      <td>-0.106391</td>\n",
       "      <td>0.039488</td>\n",
       "      <td>0.526060</td>\n",
       "      <td>0.189748</td>\n",
       "      <td>-0.747163</td>\n",
       "      <td>-0.488399</td>\n",
       "      <td>0.084417</td>\n",
       "      <td>-0.638029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096112</td>\n",
       "      <td>-0.216066</td>\n",
       "      <td>-0.146001</td>\n",
       "      <td>0.146645</td>\n",
       "      <td>-0.900364</td>\n",
       "      <td>0.018970</td>\n",
       "      <td>0.224596</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201601  0.717415 -0.264619 -0.512345 -0.596061  0.474445  0.534150 -0.046372   \n",
       "201602 -0.419614 -0.077807  0.419405 -0.042335  0.008382 -0.073435 -0.675073   \n",
       "201603  0.000901  0.118415 -0.330244 -0.239351 -0.325351  0.133311  0.349401   \n",
       "201604  0.529969 -0.509892  0.742719  0.991672 -0.387949  0.454282  0.073106   \n",
       "201605 -0.056345  0.191385 -0.106391  0.039488  0.526060  0.189748 -0.747163   \n",
       "\n",
       "               7         8         9  ...      1017      1018      1019  \\\n",
       "201601 -0.033960  0.317819  0.237751  ... -0.131012  0.127058 -0.319972   \n",
       "201602 -0.723629  0.606674 -0.262004  ... -0.122372 -0.760683 -0.018953   \n",
       "201603 -0.411326  0.111055  0.336141  ... -0.198964 -0.020205  0.130970   \n",
       "201604  0.081956  0.118748 -0.125905  ...  0.509073 -0.501989  0.615657   \n",
       "201605 -0.488399  0.084417 -0.638029  ... -0.096112 -0.216066 -0.146001   \n",
       "\n",
       "            1020      1021      1022      1023  0  1  2  \n",
       "201601  0.037591  0.106643 -0.352494 -0.615821  1  0  0  \n",
       "201602 -0.522950 -0.092673  0.164985  0.116053  0  1  0  \n",
       "201603  0.252293 -0.728723  0.270905 -0.716005  0  0  1  \n",
       "201604  0.648789 -0.508657  0.017548 -0.717804  1  0  0  \n",
       "201605  0.146645 -0.900364  0.018970  0.224596  1  0  0  \n",
       "\n",
       "[5 rows x 1027 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_range = (-1, 1)\n",
    "\n",
    "# Scale train:\n",
    "train_df, scalers = normalize_train_features(train_df, feature_range=feature_range, n_labels=n_labels)\n",
    "\n",
    "#print(f'The scalers are: {scalers}')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93651e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "0      -0.611774\n",
      "1      -0.698647\n",
      "2      -1.492308\n",
      "3      -0.577689\n",
      "4      -0.528444\n",
      "          ...   \n",
      "1022   -0.468700\n",
      "1023   -1.009303\n",
      "0       0.000000\n",
      "1       0.000000\n",
      "2       0.000000\n",
      "Length: 1027, dtype: float64\n",
      " Max values are: \n",
      "0       0.798543\n",
      "1       0.992657\n",
      "2       0.376680\n",
      "3       0.943176\n",
      "4       0.824965\n",
      "          ...   \n",
      "1022    0.451219\n",
      "1023    0.782204\n",
      "0       1.000000\n",
      "1       1.000000\n",
      "2       1.000000\n",
      "Length: 1027, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201821</th>\n",
       "      <td>0.084599</td>\n",
       "      <td>0.542881</td>\n",
       "      <td>-0.384070</td>\n",
       "      <td>-0.080906</td>\n",
       "      <td>0.138302</td>\n",
       "      <td>0.078038</td>\n",
       "      <td>-0.007716</td>\n",
       "      <td>-0.031384</td>\n",
       "      <td>-0.545694</td>\n",
       "      <td>-0.072470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699482</td>\n",
       "      <td>0.136318</td>\n",
       "      <td>0.328906</td>\n",
       "      <td>0.342614</td>\n",
       "      <td>0.063277</td>\n",
       "      <td>0.219823</td>\n",
       "      <td>0.294464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201822</th>\n",
       "      <td>0.798543</td>\n",
       "      <td>0.992657</td>\n",
       "      <td>-0.493325</td>\n",
       "      <td>-0.416277</td>\n",
       "      <td>0.266510</td>\n",
       "      <td>-0.591903</td>\n",
       "      <td>0.565659</td>\n",
       "      <td>-0.179126</td>\n",
       "      <td>0.237211</td>\n",
       "      <td>0.382436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201944</td>\n",
       "      <td>-0.673409</td>\n",
       "      <td>-0.036940</td>\n",
       "      <td>-0.021246</td>\n",
       "      <td>0.060466</td>\n",
       "      <td>0.102064</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201823</th>\n",
       "      <td>0.247549</td>\n",
       "      <td>-0.247999</td>\n",
       "      <td>0.253891</td>\n",
       "      <td>0.300498</td>\n",
       "      <td>0.187533</td>\n",
       "      <td>-0.202666</td>\n",
       "      <td>-0.067352</td>\n",
       "      <td>-0.504047</td>\n",
       "      <td>0.361369</td>\n",
       "      <td>0.378615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290135</td>\n",
       "      <td>0.185387</td>\n",
       "      <td>0.484507</td>\n",
       "      <td>-0.645408</td>\n",
       "      <td>-0.595917</td>\n",
       "      <td>-0.186724</td>\n",
       "      <td>-0.197858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201824</th>\n",
       "      <td>0.420624</td>\n",
       "      <td>0.373608</td>\n",
       "      <td>-0.799224</td>\n",
       "      <td>0.511320</td>\n",
       "      <td>-0.279726</td>\n",
       "      <td>-0.603021</td>\n",
       "      <td>0.154349</td>\n",
       "      <td>-0.543294</td>\n",
       "      <td>0.365547</td>\n",
       "      <td>0.051451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053085</td>\n",
       "      <td>-0.549938</td>\n",
       "      <td>0.159301</td>\n",
       "      <td>0.492040</td>\n",
       "      <td>-0.004100</td>\n",
       "      <td>0.447210</td>\n",
       "      <td>-0.103205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201825</th>\n",
       "      <td>0.155971</td>\n",
       "      <td>-0.698647</td>\n",
       "      <td>0.350023</td>\n",
       "      <td>-0.577689</td>\n",
       "      <td>0.674053</td>\n",
       "      <td>-0.199004</td>\n",
       "      <td>0.069916</td>\n",
       "      <td>-0.071021</td>\n",
       "      <td>0.025623</td>\n",
       "      <td>-0.410628</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164270</td>\n",
       "      <td>0.157324</td>\n",
       "      <td>-0.432406</td>\n",
       "      <td>0.355685</td>\n",
       "      <td>0.165775</td>\n",
       "      <td>0.352219</td>\n",
       "      <td>0.450566</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201821  0.084599  0.542881 -0.384070 -0.080906  0.138302  0.078038 -0.007716   \n",
       "201822  0.798543  0.992657 -0.493325 -0.416277  0.266510 -0.591903  0.565659   \n",
       "201823  0.247549 -0.247999  0.253891  0.300498  0.187533 -0.202666 -0.067352   \n",
       "201824  0.420624  0.373608 -0.799224  0.511320 -0.279726 -0.603021  0.154349   \n",
       "201825  0.155971 -0.698647  0.350023 -0.577689  0.674053 -0.199004  0.069916   \n",
       "\n",
       "               7         8         9  ...      1017      1018      1019  \\\n",
       "201821 -0.031384 -0.545694 -0.072470  ... -0.699482  0.136318  0.328906   \n",
       "201822 -0.179126  0.237211  0.382436  ...  0.201944 -0.673409 -0.036940   \n",
       "201823 -0.504047  0.361369  0.378615  ... -0.290135  0.185387  0.484507   \n",
       "201824 -0.543294  0.365547  0.051451  ... -0.053085 -0.549938  0.159301   \n",
       "201825 -0.071021  0.025623 -0.410628  ... -0.164270  0.157324 -0.432406   \n",
       "\n",
       "            1020      1021      1022      1023  0  1  2  \n",
       "201821  0.342614  0.063277  0.219823  0.294464  1  0  0  \n",
       "201822 -0.021246  0.060466  0.102064  0.112100  1  0  0  \n",
       "201823 -0.645408 -0.595917 -0.186724 -0.197858  1  0  0  \n",
       "201824  0.492040 -0.004100  0.447210 -0.103205  1  0  0  \n",
       "201825  0.355685  0.165775  0.352219  0.450566  1  0  0  \n",
       "\n",
       "[5 rows x 1027 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale test:\n",
    "test_df = normalize_test_features(test_df, scalers=scalers, n_labels=n_labels)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b854b",
   "metadata": {},
   "source": [
    "### Prepare data for time series supervised learning (function to create sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ede5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for time series\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7591806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-10)</th>\n",
       "      <th>var2(t-10)</th>\n",
       "      <th>var3(t-10)</th>\n",
       "      <th>var4(t-10)</th>\n",
       "      <th>var5(t-10)</th>\n",
       "      <th>var6(t-10)</th>\n",
       "      <th>var7(t-10)</th>\n",
       "      <th>var8(t-10)</th>\n",
       "      <th>var9(t-10)</th>\n",
       "      <th>var10(t-10)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1018(t)</th>\n",
       "      <th>var1019(t)</th>\n",
       "      <th>var1020(t)</th>\n",
       "      <th>var1021(t)</th>\n",
       "      <th>var1022(t)</th>\n",
       "      <th>var1023(t)</th>\n",
       "      <th>var1024(t)</th>\n",
       "      <th>var1025(t)</th>\n",
       "      <th>var1026(t)</th>\n",
       "      <th>var1027(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201611</th>\n",
       "      <td>0.717415</td>\n",
       "      <td>-0.264619</td>\n",
       "      <td>-0.512345</td>\n",
       "      <td>-0.596061</td>\n",
       "      <td>0.474445</td>\n",
       "      <td>0.534150</td>\n",
       "      <td>-0.046372</td>\n",
       "      <td>-0.033960</td>\n",
       "      <td>0.317819</td>\n",
       "      <td>0.237751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148737</td>\n",
       "      <td>-0.063537</td>\n",
       "      <td>0.342771</td>\n",
       "      <td>-0.026400</td>\n",
       "      <td>0.267312</td>\n",
       "      <td>-0.061181</td>\n",
       "      <td>-0.022407</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201612</th>\n",
       "      <td>-0.419614</td>\n",
       "      <td>-0.077807</td>\n",
       "      <td>0.419405</td>\n",
       "      <td>-0.042335</td>\n",
       "      <td>0.008382</td>\n",
       "      <td>-0.073435</td>\n",
       "      <td>-0.675073</td>\n",
       "      <td>-0.723629</td>\n",
       "      <td>0.606674</td>\n",
       "      <td>-0.262004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515570</td>\n",
       "      <td>-0.123022</td>\n",
       "      <td>-0.496992</td>\n",
       "      <td>0.268676</td>\n",
       "      <td>0.079583</td>\n",
       "      <td>0.241669</td>\n",
       "      <td>-0.595634</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201613</th>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.118415</td>\n",
       "      <td>-0.330244</td>\n",
       "      <td>-0.239351</td>\n",
       "      <td>-0.325351</td>\n",
       "      <td>0.133311</td>\n",
       "      <td>0.349401</td>\n",
       "      <td>-0.411326</td>\n",
       "      <td>0.111055</td>\n",
       "      <td>0.336141</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126848</td>\n",
       "      <td>0.661713</td>\n",
       "      <td>0.153685</td>\n",
       "      <td>0.229164</td>\n",
       "      <td>-0.463973</td>\n",
       "      <td>0.053713</td>\n",
       "      <td>-0.975594</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201614</th>\n",
       "      <td>0.529969</td>\n",
       "      <td>-0.509892</td>\n",
       "      <td>0.742719</td>\n",
       "      <td>0.991672</td>\n",
       "      <td>-0.387949</td>\n",
       "      <td>0.454282</td>\n",
       "      <td>0.073106</td>\n",
       "      <td>0.081956</td>\n",
       "      <td>0.118748</td>\n",
       "      <td>-0.125905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285252</td>\n",
       "      <td>-0.459350</td>\n",
       "      <td>0.118487</td>\n",
       "      <td>0.717821</td>\n",
       "      <td>0.011011</td>\n",
       "      <td>-0.017436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201615</th>\n",
       "      <td>-0.056345</td>\n",
       "      <td>0.191385</td>\n",
       "      <td>-0.106391</td>\n",
       "      <td>0.039488</td>\n",
       "      <td>0.526060</td>\n",
       "      <td>0.189748</td>\n",
       "      <td>-0.747163</td>\n",
       "      <td>-0.488399</td>\n",
       "      <td>0.084417</td>\n",
       "      <td>-0.638029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502082</td>\n",
       "      <td>-0.235513</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>0.535678</td>\n",
       "      <td>0.225521</td>\n",
       "      <td>0.046232</td>\n",
       "      <td>0.145397</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201816</th>\n",
       "      <td>0.161418</td>\n",
       "      <td>0.059350</td>\n",
       "      <td>-0.407217</td>\n",
       "      <td>-0.322475</td>\n",
       "      <td>0.280339</td>\n",
       "      <td>0.312166</td>\n",
       "      <td>0.115440</td>\n",
       "      <td>-0.833810</td>\n",
       "      <td>-0.187396</td>\n",
       "      <td>-0.351217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353747</td>\n",
       "      <td>0.397505</td>\n",
       "      <td>0.451361</td>\n",
       "      <td>-0.138578</td>\n",
       "      <td>-0.306785</td>\n",
       "      <td>0.371796</td>\n",
       "      <td>-0.192488</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201817</th>\n",
       "      <td>0.887821</td>\n",
       "      <td>-0.180743</td>\n",
       "      <td>-0.405007</td>\n",
       "      <td>-0.110293</td>\n",
       "      <td>-0.760965</td>\n",
       "      <td>0.572115</td>\n",
       "      <td>-0.546911</td>\n",
       "      <td>-0.084733</td>\n",
       "      <td>0.133753</td>\n",
       "      <td>-0.301270</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.207863</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.488648</td>\n",
       "      <td>-0.299530</td>\n",
       "      <td>-0.063334</td>\n",
       "      <td>0.803492</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201818</th>\n",
       "      <td>0.554046</td>\n",
       "      <td>0.137046</td>\n",
       "      <td>0.084558</td>\n",
       "      <td>0.011125</td>\n",
       "      <td>-0.421474</td>\n",
       "      <td>-0.790012</td>\n",
       "      <td>-0.537559</td>\n",
       "      <td>0.433995</td>\n",
       "      <td>0.491965</td>\n",
       "      <td>0.484942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160777</td>\n",
       "      <td>-0.014544</td>\n",
       "      <td>0.017891</td>\n",
       "      <td>0.102530</td>\n",
       "      <td>0.360620</td>\n",
       "      <td>-0.128165</td>\n",
       "      <td>-0.316256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201819</th>\n",
       "      <td>0.149763</td>\n",
       "      <td>-0.577400</td>\n",
       "      <td>-0.319449</td>\n",
       "      <td>-0.402680</td>\n",
       "      <td>-0.085460</td>\n",
       "      <td>-0.189519</td>\n",
       "      <td>-0.881927</td>\n",
       "      <td>0.317386</td>\n",
       "      <td>-0.189051</td>\n",
       "      <td>0.544778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255767</td>\n",
       "      <td>-0.741897</td>\n",
       "      <td>0.086524</td>\n",
       "      <td>0.102446</td>\n",
       "      <td>0.620181</td>\n",
       "      <td>0.121715</td>\n",
       "      <td>0.747221</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201820</th>\n",
       "      <td>0.588307</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.317992</td>\n",
       "      <td>-0.042756</td>\n",
       "      <td>0.269775</td>\n",
       "      <td>-0.396270</td>\n",
       "      <td>-0.482307</td>\n",
       "      <td>-0.231678</td>\n",
       "      <td>0.376478</td>\n",
       "      <td>0.264857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502141</td>\n",
       "      <td>-0.403143</td>\n",
       "      <td>-0.062169</td>\n",
       "      <td>-0.114325</td>\n",
       "      <td>-0.087839</td>\n",
       "      <td>0.094620</td>\n",
       "      <td>-0.479982</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 11297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        var1(t-10)  var2(t-10)  var3(t-10)  var4(t-10)  var5(t-10)  \\\n",
       "201611    0.717415   -0.264619   -0.512345   -0.596061    0.474445   \n",
       "201612   -0.419614   -0.077807    0.419405   -0.042335    0.008382   \n",
       "201613    0.000901    0.118415   -0.330244   -0.239351   -0.325351   \n",
       "201614    0.529969   -0.509892    0.742719    0.991672   -0.387949   \n",
       "201615   -0.056345    0.191385   -0.106391    0.039488    0.526060   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "201816    0.161418    0.059350   -0.407217   -0.322475    0.280339   \n",
       "201817    0.887821   -0.180743   -0.405007   -0.110293   -0.760965   \n",
       "201818    0.554046    0.137046    0.084558    0.011125   -0.421474   \n",
       "201819    0.149763   -0.577400   -0.319449   -0.402680   -0.085460   \n",
       "201820    0.588307    0.007995    0.317992   -0.042756    0.269775   \n",
       "\n",
       "        var6(t-10)  var7(t-10)  var8(t-10)  var9(t-10)  var10(t-10)  ...  \\\n",
       "201611    0.534150   -0.046372   -0.033960    0.317819     0.237751  ...   \n",
       "201612   -0.073435   -0.675073   -0.723629    0.606674    -0.262004  ...   \n",
       "201613    0.133311    0.349401   -0.411326    0.111055     0.336141  ...   \n",
       "201614    0.454282    0.073106    0.081956    0.118748    -0.125905  ...   \n",
       "201615    0.189748   -0.747163   -0.488399    0.084417    -0.638029  ...   \n",
       "...            ...         ...         ...         ...          ...  ...   \n",
       "201816    0.312166    0.115440   -0.833810   -0.187396    -0.351217  ...   \n",
       "201817    0.572115   -0.546911   -0.084733    0.133753    -0.301270  ...   \n",
       "201818   -0.790012   -0.537559    0.433995    0.491965     0.484942  ...   \n",
       "201819   -0.189519   -0.881927    0.317386   -0.189051     0.544778  ...   \n",
       "201820   -0.396270   -0.482307   -0.231678    0.376478     0.264857  ...   \n",
       "\n",
       "        var1018(t)  var1019(t)  var1020(t)  var1021(t)  var1022(t)  \\\n",
       "201611    0.148737   -0.063537    0.342771   -0.026400    0.267312   \n",
       "201612    0.515570   -0.123022   -0.496992    0.268676    0.079583   \n",
       "201613   -0.126848    0.661713    0.153685    0.229164   -0.463973   \n",
       "201614    0.285252   -0.459350    0.118487    0.717821    0.011011   \n",
       "201615    0.502082   -0.235513    0.015692    0.535678    0.225521   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "201816    0.353747    0.397505    0.451361   -0.138578   -0.306785   \n",
       "201817   -1.000000   -0.207863    0.403494    0.488648   -0.299530   \n",
       "201818   -0.160777   -0.014544    0.017891    0.102530    0.360620   \n",
       "201819    0.255767   -0.741897    0.086524    0.102446    0.620181   \n",
       "201820    0.502141   -0.403143   -0.062169   -0.114325   -0.087839   \n",
       "\n",
       "        var1023(t)  var1024(t)  var1025(t)  var1026(t)  var1027(t)  \n",
       "201611   -0.061181   -0.022407           0           1           0  \n",
       "201612    0.241669   -0.595634           0           1           0  \n",
       "201613    0.053713   -0.975594           0           1           0  \n",
       "201614   -0.017436    1.000000           0           0           1  \n",
       "201615    0.046232    0.145397           0           1           0  \n",
       "...            ...         ...         ...         ...         ...  \n",
       "201816    0.371796   -0.192488           1           0           0  \n",
       "201817   -0.063334    0.803492           1           0           0  \n",
       "201818   -0.128165   -0.316256           1           0           0  \n",
       "201819    0.121715    0.747221           1           0           0  \n",
       "201820    0.094620   -0.479982           1           0           0  \n",
       "\n",
       "[114 rows x 11297 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of window\n",
    "days = 10\n",
    "\n",
    "# frame as supervised learning\n",
    "train = series_to_supervised(train_df, n_in=days)\n",
    "test = series_to_supervised(test_df, n_in=days)\n",
    "\n",
    "DataFrame(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d7b62",
   "metadata": {},
   "source": [
    "### Features and Labels Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "224111dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_set(timeseries_data, original_df, n_labels):\n",
    "    \n",
    "    \"\"\" Features \"\"\"\n",
    "    # We define the number of features as (features and labels)\n",
    "    n_features = original_df.shape[1]\n",
    "\n",
    "    # The features to train the model will be all except the values of the actual week \n",
    "    # We can't use other variables in week t because whe need to resample a a 3D Array\n",
    "    features_set = DataFrame(timeseries_data.values[:,:-n_features])\n",
    "    # Convert pandas data frame to np.array to reshape as 3D Array\n",
    "    features_set = features_set.to_numpy()\n",
    "    print(f'The shape of the features is {features_set.shape}')\n",
    "    \n",
    "    \"\"\" Labels \"\"\"\n",
    "    # We will use labels in last week \n",
    "    labels_set = DataFrame(timeseries_data.values[:,-n_labels:])\n",
    "    # Convert pandas data frame to np.array\n",
    "    labels_set = labels_set.to_numpy()\n",
    "    print(f'The shape of the labels is {labels_set.shape}')\n",
    "    \n",
    "    return features_set, labels_set, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61209914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "The shape of the features is (114, 10270)\n",
      "The shape of the labels is (114, 3)\n",
      "Test:\n",
      "The shape of the features is (22, 10270)\n",
      "The shape of the labels is (22, 3)\n"
     ]
    }
   ],
   "source": [
    "# Train features and labels set\n",
    "print('Train:')\n",
    "train_X, train_y, n_features = features_labels_set(timeseries_data=train, original_df=dengue_df, n_labels=n_labels)\n",
    "\n",
    "# Test features and labels set\n",
    "print('Test:')\n",
    "test_X, test_y, n_features = features_labels_set(timeseries_data=test, original_df=dengue_df, n_labels=n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d70823a",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5f40e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tensor(train_X, test_X, n_features):\n",
    "    print('The initial shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], days, n_features))\n",
    "    test_X = test_X.reshape((test_X.shape[0], days, n_features))\n",
    "    \n",
    "    print('-----------------------')\n",
    "    print('The Final shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    return train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8487f79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial shapes are:\n",
      "The train shape is (114, 10270)\n",
      "The test shape is (22, 10270)\n",
      "-----------------------\n",
      "The Final shapes are:\n",
      "The train shape is (114, 10, 1027)\n",
      "The test shape is (22, 10, 1027)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X, test_X = reshape_tensor(train_X, test_X, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b59641",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f4042c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "#tf.random.set_seed(0)\n",
    "\n",
    "def create_model():\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(120, dropout=0.1, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "    model.add(LSTM(240, dropout=0.1, input_shape=(train_X.shape[1], 120)))\n",
    "    model.add(Dense(60))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # Compile the model:\n",
    "    opt = keras.optimizers.Adam()\n",
    "    metrics = [\n",
    "        tf.keras.metrics.AUC(name='auc', multi_label=True, num_labels=3),\n",
    "        tf.keras.metrics.CategoricalAccuracy(name='acc'),\n",
    "        tf.keras.metrics.CategoricalCrossentropy(name='entropy')\n",
    "    ]\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b1b83e",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "984a4c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# EarlyStopping:\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f22620e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros: 113, ones: 20, twos: 23, total: 156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 1.3805309734513274, 1: 7.8, 2: 6.782608695652174}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Imbalanced data\n",
    "n_zeros = (labels_df_orig.to_numpy() == 0).sum()\n",
    "n_ones = (labels_df_orig.to_numpy() == 1).sum()\n",
    "n_twos = (labels_df_orig.to_numpy() == 2).sum()\n",
    "n_total = n_zeros + n_ones + n_twos\n",
    "\n",
    "weights = {0: n_total/n_zeros, 1: n_total/n_ones, 2: n_total/n_twos}\n",
    "print(f'zeros: {n_zeros}, ones: {n_ones}, twos: {n_twos}, total: {n_total}')\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e818d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "def train_model(model, monitor, weights, plot=None, epochs=20):\n",
    "    if monitor and weights:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor], class_weight=weights)\n",
    "    elif monitor:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor])\n",
    "    elif weights:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, class_weight=weights)\n",
    "    else:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    \n",
    "    if plot:\n",
    "        # plot history\n",
    "        plt.plot(history.history['loss'], label='train')\n",
    "        plt.plot(history.history['val_loss'], label='validation')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba261de1",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d41008",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b2ad521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also evaluate or predict on a dataset.\n",
    "def evaluate(model, verbose = None):\n",
    "    if verbose:\n",
    "        print('Evaluate: ')\n",
    "    result = model.evaluate(test_X, test_y)\n",
    "    stored_results = {}\n",
    "    for i, metric in enumerate(model.metrics_names):\n",
    "        stored_results[metric] = result[i]\n",
    "        if verbose:\n",
    "            print(f'{metric}: {result[i]}')\n",
    "    return stored_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b47d4d",
   "metadata": {},
   "source": [
    "# Calculate Mean and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a51a287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(weights):\n",
    "    \n",
    "    metrics = {\n",
    "        \"auc\": [],\n",
    "        \"acc\": [],\n",
    "        \"entropy\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(3):\n",
    "        model = create_model()\n",
    "        train_model(model=model, monitor=monitor, weights=weights)\n",
    "        stored_results = evaluate(model=model)\n",
    "        \n",
    "        for key in metrics.keys():\n",
    "            metrics[key].append(stored_results[key])\n",
    "            \n",
    "    for key in metrics.keys():\n",
    "        results = metrics[key]\n",
    "        print(key, f\": average={np.average(results):.3f}, std={np.std(results):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a07926c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 - 4s - loss: 0.8913 - auc: 0.6222 - acc: 0.5789 - entropy: 0.8913 - val_loss: 0.7399 - val_auc: 0.4349 - val_acc: 0.8636 - val_entropy: 0.7399\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 1.1265 - auc: 0.4144 - acc: 0.6930 - entropy: 1.1265 - val_loss: 0.8214 - val_auc: 0.5566 - val_acc: 0.8636 - val_entropy: 0.8214\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.6654 - auc: 0.8601 - acc: 0.7281 - entropy: 0.6654 - val_loss: 0.5294 - val_auc: 0.5357 - val_acc: 0.8636 - val_entropy: 0.5294\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.5560 - auc: 0.8797 - acc: 0.7895 - entropy: 0.5560 - val_loss: 0.5047 - val_auc: 0.5912 - val_acc: 0.8636 - val_entropy: 0.5047\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.5189 - auc: 0.9027 - acc: 0.7807 - entropy: 0.5189 - val_loss: 0.5227 - val_auc: 0.6087 - val_acc: 0.8636 - val_entropy: 0.5227\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.4780 - auc: 0.9183 - acc: 0.7982 - entropy: 0.4780 - val_loss: 0.4932 - val_auc: 0.6133 - val_acc: 0.8636 - val_entropy: 0.4932\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.4344 - auc: 0.9268 - acc: 0.8158 - entropy: 0.4344 - val_loss: 0.4994 - val_auc: 0.7394 - val_acc: 0.8636 - val_entropy: 0.4994\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.3723 - auc: 0.9595 - acc: 0.8333 - entropy: 0.3723 - val_loss: 0.5778 - val_auc: 0.7051 - val_acc: 0.8636 - val_entropy: 0.5778\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.2913 - auc: 0.9756 - acc: 0.8421 - entropy: 0.2913 - val_loss: 0.7262 - val_auc: 0.5964 - val_acc: 0.8636 - val_entropy: 0.7262\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.4670 - auc: 0.9295 - acc: 0.8421 - entropy: 0.4670 - val_loss: 0.9484 - val_auc: 0.5000 - val_acc: 0.8636 - val_entropy: 0.9484\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.6419 - auc: 0.8725 - acc: 0.7719 - entropy: 0.6419 - val_loss: 0.5246 - val_auc: 0.7723 - val_acc: 0.8636 - val_entropy: 0.5246\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.5415 - auc: 0.9358 - acc: 0.8070 - entropy: 0.5415 - val_loss: 0.5731 - val_auc: 0.8074 - val_acc: 0.8636 - val_entropy: 0.5731\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.3756 - auc: 0.9574 - acc: 0.8596 - entropy: 0.3756 - val_loss: 0.4910 - val_auc: 0.7949 - val_acc: 0.8636 - val_entropy: 0.4910\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.3051 - auc: 0.9770 - acc: 0.8772 - entropy: 0.3051 - val_loss: 0.4628 - val_auc: 0.7256 - val_acc: 0.8636 - val_entropy: 0.4628\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.2526 - auc: 0.9857 - acc: 0.9123 - entropy: 0.2526 - val_loss: 0.5142 - val_auc: 0.7318 - val_acc: 0.8636 - val_entropy: 0.5142\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.1688 - auc: 0.9970 - acc: 0.9649 - entropy: 0.1688 - val_loss: 0.6669 - val_auc: 0.5673 - val_acc: 0.8636 - val_entropy: 0.6669\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.1242 - auc: 0.9977 - acc: 0.9649 - entropy: 0.1242 - val_loss: 0.8148 - val_auc: 0.4508 - val_acc: 0.8636 - val_entropy: 0.8148\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.0769 - auc: 1.0000 - acc: 1.0000 - entropy: 0.0769 - val_loss: 0.9570 - val_auc: 0.4829 - val_acc: 0.8636 - val_entropy: 0.9570\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.0752 - auc: 0.9984 - acc: 0.9825 - entropy: 0.0752 - val_loss: 1.2017 - val_auc: 0.5000 - val_acc: 0.8636 - val_entropy: 1.2017\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.2334 - auc: 0.9934 - acc: 0.9035 - entropy: 0.2334 - val_loss: 0.7130 - val_auc: 0.7772 - val_acc: 0.7727 - val_entropy: 0.7130\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7130 - auc: 0.7772 - acc: 0.7727 - entropy: 0.7130\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 0.8984 - auc: 0.6231 - acc: 0.5526 - entropy: 0.8984 - val_loss: 0.7544 - val_auc: 0.4503 - val_acc: 0.8636 - val_entropy: 0.7544\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 1.0855 - auc: 0.4443 - acc: 0.6930 - entropy: 1.0855 - val_loss: 0.8173 - val_auc: 0.5596 - val_acc: 0.8636 - val_entropy: 0.8173\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.6561 - auc: 0.8640 - acc: 0.7281 - entropy: 0.6561 - val_loss: 0.5240 - val_auc: 0.5296 - val_acc: 0.8636 - val_entropy: 0.5240\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.5593 - auc: 0.8853 - acc: 0.7895 - entropy: 0.5593 - val_loss: 0.5087 - val_auc: 0.5931 - val_acc: 0.8636 - val_entropy: 0.5087\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.4957 - auc: 0.9097 - acc: 0.7895 - entropy: 0.4957 - val_loss: 0.5451 - val_auc: 0.6515 - val_acc: 0.8636 - val_entropy: 0.5451\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.4592 - auc: 0.9251 - acc: 0.7807 - entropy: 0.4592 - val_loss: 0.5291 - val_auc: 0.4281 - val_acc: 0.8636 - val_entropy: 0.5291\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.4102 - auc: 0.9382 - acc: 0.7982 - entropy: 0.4102 - val_loss: 0.5301 - val_auc: 0.6574 - val_acc: 0.8636 - val_entropy: 0.5301\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.3650 - auc: 0.9567 - acc: 0.8421 - entropy: 0.3650 - val_loss: 0.6388 - val_auc: 0.3771 - val_acc: 0.8636 - val_entropy: 0.6388\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.4068 - auc: 0.9402 - acc: 0.7982 - entropy: 0.4068 - val_loss: 0.5977 - val_auc: 0.6582 - val_acc: 0.8636 - val_entropy: 0.5977\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.5491 - auc: 0.9253 - acc: 0.7368 - entropy: 0.5491 - val_loss: 0.6313 - val_auc: 0.4431 - val_acc: 0.8636 - val_entropy: 0.6313\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.3522 - auc: 0.9616 - acc: 0.8158 - entropy: 0.3522 - val_loss: 0.5877 - val_auc: 0.4348 - val_acc: 0.8636 - val_entropy: 0.5877\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.3076 - auc: 0.9799 - acc: 0.8684 - entropy: 0.3076 - val_loss: 0.6106 - val_auc: 0.6703 - val_acc: 0.8636 - val_entropy: 0.6106\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.2477 - auc: 0.9886 - acc: 0.9386 - entropy: 0.2477 - val_loss: 0.7106 - val_auc: 0.5065 - val_acc: 0.8636 - val_entropy: 0.7106\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.1701 - auc: 0.9970 - acc: 0.9561 - entropy: 0.1701 - val_loss: 0.8285 - val_auc: 0.6731 - val_acc: 0.8636 - val_entropy: 0.8285\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.1459 - auc: 0.9958 - acc: 0.9474 - entropy: 0.1459 - val_loss: 1.2262 - val_auc: 0.4829 - val_acc: 0.8636 - val_entropy: 1.2262\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.2027 - auc: 0.9864 - acc: 0.9298 - entropy: 0.2027 - val_loss: 1.0665 - val_auc: 0.7824 - val_acc: 0.8636 - val_entropy: 1.0665\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.3210 - auc: 0.9628 - acc: 0.9123 - entropy: 0.3210 - val_loss: 0.7248 - val_auc: 0.7356 - val_acc: 0.8636 - val_entropy: 0.7248\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.1215 - auc: 0.9956 - acc: 0.9737 - entropy: 0.1215 - val_loss: 0.5147 - val_auc: 0.5620 - val_acc: 0.8636 - val_entropy: 0.5147\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.0880 - auc: 0.9996 - acc: 0.9737 - entropy: 0.0880 - val_loss: 0.7054 - val_auc: 0.3803 - val_acc: 0.8636 - val_entropy: 0.7054\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.0509 - auc: 1.0000 - acc: 0.9912 - entropy: 0.0509 - val_loss: 0.8328 - val_auc: 0.3762 - val_acc: 0.8636 - val_entropy: 0.8328\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8328 - auc: 0.3762 - acc: 0.8636 - entropy: 0.8328\n",
      "Epoch 1/20\n",
      "8/8 - 4s - loss: 0.9299 - auc: 0.6006 - acc: 0.6404 - entropy: 0.9299 - val_loss: 0.7178 - val_auc: 0.5827 - val_acc: 0.8636 - val_entropy: 0.7178\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 1.0927 - auc: 0.4843 - acc: 0.6930 - entropy: 1.0927 - val_loss: 0.7789 - val_auc: 0.5980 - val_acc: 0.8636 - val_entropy: 0.7789\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.6734 - auc: 0.8565 - acc: 0.7281 - entropy: 0.6734 - val_loss: 0.5885 - val_auc: 0.6025 - val_acc: 0.8636 - val_entropy: 0.5885\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.5533 - auc: 0.8759 - acc: 0.7719 - entropy: 0.5533 - val_loss: 0.4910 - val_auc: 0.6471 - val_acc: 0.8636 - val_entropy: 0.4910\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.5383 - auc: 0.8919 - acc: 0.7807 - entropy: 0.5383 - val_loss: 0.5145 - val_auc: 0.6609 - val_acc: 0.8636 - val_entropy: 0.5145\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.4862 - auc: 0.9168 - acc: 0.7807 - entropy: 0.4862 - val_loss: 0.4968 - val_auc: 0.6213 - val_acc: 0.8636 - val_entropy: 0.4968\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.4368 - auc: 0.9289 - acc: 0.7895 - entropy: 0.4368 - val_loss: 0.4824 - val_auc: 0.6117 - val_acc: 0.8636 - val_entropy: 0.4824\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.3852 - auc: 0.9451 - acc: 0.8246 - entropy: 0.3852 - val_loss: 0.5127 - val_auc: 0.7102 - val_acc: 0.8636 - val_entropy: 0.5127\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.3279 - auc: 0.9665 - acc: 0.8684 - entropy: 0.3279 - val_loss: 0.6516 - val_auc: 0.4211 - val_acc: 0.8636 - val_entropy: 0.6516\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.4002 - auc: 0.9442 - acc: 0.8246 - entropy: 0.4002 - val_loss: 0.6865 - val_auc: 0.8203 - val_acc: 0.8636 - val_entropy: 0.6865\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.8374 - auc: 0.8916 - acc: 0.7544 - entropy: 0.8374 - val_loss: 0.5399 - val_auc: 0.4450 - val_acc: 0.8636 - val_entropy: 0.5399\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.5237 - auc: 0.9158 - acc: 0.7368 - entropy: 0.5237 - val_loss: 0.5286 - val_auc: 0.5451 - val_acc: 0.8636 - val_entropy: 0.5286\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.3612 - auc: 0.9670 - acc: 0.8158 - entropy: 0.3612 - val_loss: 0.5926 - val_auc: 0.6825 - val_acc: 0.8636 - val_entropy: 0.5926\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.3262 - auc: 0.9766 - acc: 0.8421 - entropy: 0.3262 - val_loss: 0.5711 - val_auc: 0.7113 - val_acc: 0.8636 - val_entropy: 0.5711\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.2438 - auc: 0.9919 - acc: 0.9386 - entropy: 0.2438 - val_loss: 0.6009 - val_auc: 0.7538 - val_acc: 0.8636 - val_entropy: 0.6009\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.1892 - auc: 0.9964 - acc: 0.9561 - entropy: 0.1892 - val_loss: 0.7917 - val_auc: 0.6934 - val_acc: 0.8636 - val_entropy: 0.7917\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.1334 - auc: 0.9987 - acc: 0.9649 - entropy: 0.1334 - val_loss: 0.9459 - val_auc: 0.5000 - val_acc: 0.8636 - val_entropy: 0.9459\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.0861 - auc: 0.9996 - acc: 0.9825 - entropy: 0.0861 - val_loss: 1.3356 - val_auc: 0.5000 - val_acc: 0.8636 - val_entropy: 1.3356\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.1336 - auc: 0.9930 - acc: 0.9649 - entropy: 0.1336 - val_loss: 0.7426 - val_auc: 0.6964 - val_acc: 0.8636 - val_entropy: 0.7426\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.2642 - auc: 0.9791 - acc: 0.9035 - entropy: 0.2642 - val_loss: 0.8252 - val_auc: 0.6956 - val_acc: 0.8636 - val_entropy: 0.8252\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8252 - auc: 0.6956 - acc: 0.8636 - entropy: 0.8252\n",
      "auc : average=0.616, std=0.173\n",
      "acc : average=0.833, std=0.043\n",
      "entropy : average=0.790, std=0.055\n"
     ]
    }
   ],
   "source": [
    "calculate_mean_std(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60d05610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 - 4s - loss: 3.7187 - auc: 0.4278 - acc: 0.1404 - entropy: 1.3161 - val_loss: 0.8382 - val_auc: 0.4418 - val_acc: 0.8636 - val_entropy: 0.8382\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 3.2781 - auc: 0.7681 - acc: 0.7281 - entropy: 0.7752 - val_loss: 0.9604 - val_auc: 0.6713 - val_acc: 0.5909 - val_entropy: 0.9604\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 2.4535 - auc: 0.8391 - acc: 0.6842 - entropy: 0.8707 - val_loss: 0.7689 - val_auc: 0.7263 - val_acc: 0.8636 - val_entropy: 0.7689\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 2.0854 - auc: 0.8986 - acc: 0.7368 - entropy: 0.6386 - val_loss: 0.7518 - val_auc: 0.7843 - val_acc: 0.8636 - val_entropy: 0.7518\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 1.8078 - auc: 0.9124 - acc: 0.7105 - entropy: 0.6931 - val_loss: 0.4753 - val_auc: 0.8201 - val_acc: 0.8636 - val_entropy: 0.4753\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 1.4700 - auc: 0.9424 - acc: 0.7807 - entropy: 0.4670 - val_loss: 0.4278 - val_auc: 0.8377 - val_acc: 0.8636 - val_entropy: 0.4278\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 1.5012 - auc: 0.9262 - acc: 0.6930 - entropy: 0.6939 - val_loss: 0.6115 - val_auc: 0.7211 - val_acc: 0.8636 - val_entropy: 0.6115\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 2.7585 - auc: 0.9084 - acc: 0.7281 - entropy: 0.6367 - val_loss: 0.8942 - val_auc: 0.6646 - val_acc: 0.5455 - val_entropy: 0.8942\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 1.6799 - auc: 0.9424 - acc: 0.5877 - entropy: 0.8083 - val_loss: 0.9632 - val_auc: 0.6708 - val_acc: 0.4545 - val_entropy: 0.9632\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 1.4233 - auc: 0.9475 - acc: 0.7281 - entropy: 0.5703 - val_loss: 0.6563 - val_auc: 0.6382 - val_acc: 0.8636 - val_entropy: 0.6563\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 1.1252 - auc: 0.9630 - acc: 0.8158 - entropy: 0.4062 - val_loss: 0.5118 - val_auc: 0.6899 - val_acc: 0.8636 - val_entropy: 0.5118\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.8472 - auc: 0.9788 - acc: 0.8158 - entropy: 0.3805 - val_loss: 0.4608 - val_auc: 0.7158 - val_acc: 0.8636 - val_entropy: 0.4608\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.6388 - auc: 0.9842 - acc: 0.8860 - entropy: 0.2899 - val_loss: 0.5011 - val_auc: 0.7403 - val_acc: 0.8636 - val_entropy: 0.5011\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.4928 - auc: 0.9912 - acc: 0.8947 - entropy: 0.2327 - val_loss: 0.6169 - val_auc: 0.6828 - val_acc: 0.8636 - val_entropy: 0.6169\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.4090 - auc: 0.9897 - acc: 0.9211 - entropy: 0.2127 - val_loss: 0.8519 - val_auc: 0.4921 - val_acc: 0.8636 - val_entropy: 0.8519\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.4646 - auc: 0.9905 - acc: 0.9298 - entropy: 0.1995 - val_loss: 0.5061 - val_auc: 0.6590 - val_acc: 0.8636 - val_entropy: 0.5061\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.4813 - auc: 0.9847 - acc: 0.9386 - entropy: 0.2880 - val_loss: 0.5559 - val_auc: 0.6548 - val_acc: 0.8636 - val_entropy: 0.5559\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.3808 - auc: 0.9979 - acc: 0.9035 - entropy: 0.2419 - val_loss: 0.6260 - val_auc: 0.6106 - val_acc: 0.8636 - val_entropy: 0.6260\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.2392 - auc: 0.9993 - acc: 0.9474 - entropy: 0.0962 - val_loss: 0.5163 - val_auc: 0.6461 - val_acc: 0.8636 - val_entropy: 0.5163\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.2424 - auc: 0.9988 - acc: 0.9474 - entropy: 0.1412 - val_loss: 0.5272 - val_auc: 0.6473 - val_acc: 0.8636 - val_entropy: 0.5272\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5272 - auc: 0.6473 - acc: 0.8636 - entropy: 0.5272\n",
      "Epoch 1/20\n",
      "8/8 - 4s - loss: 3.7630 - auc: 0.4128 - acc: 0.1228 - entropy: 1.3353 - val_loss: 0.8150 - val_auc: 0.4208 - val_acc: 0.8636 - val_entropy: 0.8150\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 3.2179 - auc: 0.7540 - acc: 0.7368 - entropy: 0.8058 - val_loss: 0.9181 - val_auc: 0.6964 - val_acc: 0.8182 - val_entropy: 0.9181\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 2.5947 - auc: 0.8302 - acc: 0.6930 - entropy: 0.8711 - val_loss: 0.7326 - val_auc: 0.7998 - val_acc: 0.8636 - val_entropy: 0.7326\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 2.1225 - auc: 0.8976 - acc: 0.7456 - entropy: 0.6244 - val_loss: 0.7371 - val_auc: 0.7839 - val_acc: 0.8636 - val_entropy: 0.7371\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 1.8457 - auc: 0.9164 - acc: 0.6842 - entropy: 0.7091 - val_loss: 0.4976 - val_auc: 0.8473 - val_acc: 0.8636 - val_entropy: 0.4976\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 1.5207 - auc: 0.9381 - acc: 0.7982 - entropy: 0.4678 - val_loss: 0.5273 - val_auc: 0.8337 - val_acc: 0.8636 - val_entropy: 0.5273\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 1.6868 - auc: 0.9130 - acc: 0.7018 - entropy: 0.7959 - val_loss: 0.6024 - val_auc: 0.7931 - val_acc: 0.8636 - val_entropy: 0.6024\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 2.3432 - auc: 0.9233 - acc: 0.7456 - entropy: 0.5479 - val_loss: 0.9275 - val_auc: 0.6691 - val_acc: 0.5909 - val_entropy: 0.9275\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 1.9851 - auc: 0.9192 - acc: 0.5439 - entropy: 0.9910 - val_loss: 1.1280 - val_auc: 0.6895 - val_acc: 0.3636 - val_entropy: 1.1280\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 1.5439 - auc: 0.9471 - acc: 0.6404 - entropy: 0.7540 - val_loss: 0.8453 - val_auc: 0.7917 - val_acc: 0.8182 - val_entropy: 0.8453\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 1.1841 - auc: 0.9591 - acc: 0.7982 - entropy: 0.4975 - val_loss: 0.5128 - val_auc: 0.7875 - val_acc: 0.8636 - val_entropy: 0.5128\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.9568 - auc: 0.9733 - acc: 0.8596 - entropy: 0.3646 - val_loss: 0.4592 - val_auc: 0.7850 - val_acc: 0.8636 - val_entropy: 0.4592\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.7209 - auc: 0.9854 - acc: 0.8246 - entropy: 0.3722 - val_loss: 0.4315 - val_auc: 0.7858 - val_acc: 0.8636 - val_entropy: 0.4315\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.5441 - auc: 0.9900 - acc: 0.8947 - entropy: 0.2545 - val_loss: 0.5142 - val_auc: 0.7692 - val_acc: 0.8636 - val_entropy: 0.5142\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.4107 - auc: 0.9932 - acc: 0.9035 - entropy: 0.2152 - val_loss: 0.6948 - val_auc: 0.7129 - val_acc: 0.8636 - val_entropy: 0.6948\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.5800 - auc: 0.9838 - acc: 0.9035 - entropy: 0.2580 - val_loss: 0.4779 - val_auc: 0.6761 - val_acc: 0.8636 - val_entropy: 0.4779\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.7931 - auc: 0.9672 - acc: 0.9211 - entropy: 0.4838 - val_loss: 0.5043 - val_auc: 0.6256 - val_acc: 0.8636 - val_entropy: 0.5043\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.4974 - auc: 0.9888 - acc: 0.8860 - entropy: 0.3353 - val_loss: 0.4928 - val_auc: 0.6519 - val_acc: 0.8636 - val_entropy: 0.4928\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.3241 - auc: 0.9971 - acc: 0.9474 - entropy: 0.1431 - val_loss: 0.4929 - val_auc: 0.6824 - val_acc: 0.8636 - val_entropy: 0.4929\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.3065 - auc: 0.9954 - acc: 0.9211 - entropy: 0.1743 - val_loss: 0.5114 - val_auc: 0.6949 - val_acc: 0.8636 - val_entropy: 0.5114\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5114 - auc: 0.6949 - acc: 0.8636 - entropy: 0.5114\n",
      "Epoch 1/20\n",
      "8/8 - 4s - loss: 3.7896 - auc: 0.3509 - acc: 0.1404 - entropy: 1.3437 - val_loss: 1.0031 - val_auc: 0.4647 - val_acc: 0.3182 - val_entropy: 1.0031\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 3.1154 - auc: 0.8005 - acc: 0.7018 - entropy: 0.8219 - val_loss: 0.8884 - val_auc: 0.4906 - val_acc: 0.6364 - val_entropy: 0.8884\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 2.4932 - auc: 0.8457 - acc: 0.7281 - entropy: 0.7264 - val_loss: 0.7931 - val_auc: 0.6293 - val_acc: 0.8636 - val_entropy: 0.7931\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 2.0981 - auc: 0.8873 - acc: 0.7105 - entropy: 0.6738 - val_loss: 0.8123 - val_auc: 0.5645 - val_acc: 0.8636 - val_entropy: 0.8123\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 1.7444 - auc: 0.9239 - acc: 0.6930 - entropy: 0.6133 - val_loss: 0.5321 - val_auc: 0.6339 - val_acc: 0.8636 - val_entropy: 0.5321\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 1.4962 - auc: 0.9359 - acc: 0.7895 - entropy: 0.4578 - val_loss: 0.8915 - val_auc: 0.5399 - val_acc: 0.6364 - val_entropy: 0.8915\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 1.6785 - auc: 0.9082 - acc: 0.6491 - entropy: 0.9512 - val_loss: 0.6435 - val_auc: 0.2622 - val_acc: 0.8636 - val_entropy: 0.6435\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 3.2651 - auc: 0.8179 - acc: 0.7368 - entropy: 0.7302 - val_loss: 1.3234 - val_auc: 0.7143 - val_acc: 0.0909 - val_entropy: 1.3234\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 2.1533 - auc: 0.8887 - acc: 0.5965 - entropy: 0.8573 - val_loss: 0.9207 - val_auc: 0.6961 - val_acc: 0.6818 - val_entropy: 0.9207\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 1.6375 - auc: 0.9281 - acc: 0.7544 - entropy: 0.6470 - val_loss: 0.7840 - val_auc: 0.6810 - val_acc: 0.6364 - val_entropy: 0.7840\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 1.1240 - auc: 0.9554 - acc: 0.8158 - entropy: 0.4612 - val_loss: 0.7118 - val_auc: 0.6713 - val_acc: 0.7273 - val_entropy: 0.7118\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.8674 - auc: 0.9767 - acc: 0.8333 - entropy: 0.3863 - val_loss: 0.4955 - val_auc: 0.7827 - val_acc: 0.8636 - val_entropy: 0.4955\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.6589 - auc: 0.9830 - acc: 0.8684 - entropy: 0.3197 - val_loss: 0.4244 - val_auc: 0.8303 - val_acc: 0.8636 - val_entropy: 0.4244\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.5037 - auc: 0.9902 - acc: 0.8947 - entropy: 0.2497 - val_loss: 0.4661 - val_auc: 0.7376 - val_acc: 0.8636 - val_entropy: 0.4661\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.4802 - auc: 0.9880 - acc: 0.9035 - entropy: 0.2500 - val_loss: 0.5057 - val_auc: 0.8732 - val_acc: 0.8636 - val_entropy: 0.5057\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.4701 - auc: 0.9874 - acc: 0.9035 - entropy: 0.2277 - val_loss: 0.5663 - val_auc: 0.6963 - val_acc: 0.8182 - val_entropy: 0.5663\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.4085 - auc: 0.9920 - acc: 0.9035 - entropy: 0.2497 - val_loss: 0.7276 - val_auc: 0.8908 - val_acc: 0.8636 - val_entropy: 0.7276\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.2632 - auc: 0.9976 - acc: 0.9474 - entropy: 0.1036 - val_loss: 0.5007 - val_auc: 0.8436 - val_acc: 0.8636 - val_entropy: 0.5007\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.1800 - auc: 0.9997 - acc: 0.9561 - entropy: 0.0978 - val_loss: 0.5096 - val_auc: 0.7956 - val_acc: 0.8636 - val_entropy: 0.5096\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.1549 - auc: 0.9998 - acc: 0.9825 - entropy: 0.0688 - val_loss: 0.4767 - val_auc: 0.8533 - val_acc: 0.8636 - val_entropy: 0.4767\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4767 - auc: 0.8533 - acc: 0.8636 - entropy: 0.4767\n",
      "auc : average=0.732, std=0.088\n",
      "acc : average=0.864, std=0.000\n",
      "entropy : average=0.505, std=0.021\n"
     ]
    }
   ],
   "source": [
    "calculate_mean_std(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1ec5ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = create_model()\n",
    "#train_model(model=model, monitor=monitor, weights=weights)\n",
    "#stored_results = evaluate(model=model)\n",
    "#print(stored_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ebf5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
