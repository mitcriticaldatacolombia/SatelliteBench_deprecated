{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd0f570",
   "metadata": {},
   "source": [
    "# Setup enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba9e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading in Dataframe format and data preprocessing\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Linear algebra operations\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning models and preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "\n",
    "# Epiweek\n",
    "from epiweeks import Week, Year\n",
    "\n",
    "# Date\n",
    "from datetime import date as convert_to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d72be795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d1aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = 'Embeddings/embeddings_autoencoder_1024features.csv'\n",
    "labels = 'Tabular_data/Label_CSV_All_Municipality.csv'\n",
    "MUNICIPALITY = 'Ibagué'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f7b227",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6762cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epiweek_from_date(image_date):\n",
    "    date = image_date.split('-')\n",
    "    \n",
    "    # Get year as int\n",
    "    year = ''.join(filter(str.isdigit, date[0]))\n",
    "    year = int(year)\n",
    "    \n",
    "    # Get month as int\n",
    "    month = ''.join(filter(str.isdigit, date[1]))\n",
    "    month = int(month)\n",
    "    \n",
    "    # Get day as int\n",
    "    day = ''.join(filter(str.isdigit, date[2]))\n",
    "    day = int(day)\n",
    "    \n",
    "    # Get epiweek:\n",
    "    date = convert_to_date(year, month, day)\n",
    "    epiweek = str(Week.fromdate(date))\n",
    "    epiweek = int(epiweek)\n",
    "    \n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d26ecae",
   "metadata": {},
   "source": [
    "### 1. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a48ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_features(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    #df.Date = pd.to_datetime(df.Date)\n",
    "    \n",
    "    if Municipality:\n",
    "        print('Obtaining dataframe for the city of Medellin only...')\n",
    "        df = df[df['Municipality Code'] == Municipality]\n",
    "        \n",
    "    df.Date = df.Date.apply(epiweek_from_date)\n",
    "    \n",
    "    df = df.sort_values(by=['Date'])\n",
    "    \n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    if Municipality:\n",
    "        df.drop(columns=['Municipality Code'], inplace=True)\n",
    "        \n",
    "    df.index.name = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d56ae31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining dataframe for the city of Medellin only...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201544</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.194829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.783459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.06569</td>\n",
       "      <td>14.480082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.28792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.770391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.103770</td>\n",
       "      <td>22.228394</td>\n",
       "      <td>14.962168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201545</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.194829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.783459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.06569</td>\n",
       "      <td>14.480082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.28792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.770391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.103770</td>\n",
       "      <td>22.228394</td>\n",
       "      <td>14.962168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201546</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.194829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.783459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.06569</td>\n",
       "      <td>14.480082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.28792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.770391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.103770</td>\n",
       "      <td>22.228394</td>\n",
       "      <td>14.962168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201547</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.194829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.783459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.06569</td>\n",
       "      <td>14.480082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.28792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.770391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.103770</td>\n",
       "      <td>22.228394</td>\n",
       "      <td>14.962168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201548</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.194829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.783459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.06569</td>\n",
       "      <td>14.480082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.28792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.770391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.103770</td>\n",
       "      <td>22.228394</td>\n",
       "      <td>14.962168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>0.0</td>\n",
       "      <td>162.968550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>483.99040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.917923</td>\n",
       "      <td>194.997240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.883835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60.541855</td>\n",
       "      <td>93.76406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.353489</td>\n",
       "      <td>95.447860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>393.65164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.705810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.526907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.732930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.92910</td>\n",
       "      <td>23.647943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.74010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.985338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.885499</td>\n",
       "      <td>10.678081</td>\n",
       "      <td>32.098557</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>248.88963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.782180</td>\n",
       "      <td>21.635462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0           1    2    3          4    5          6    7         8  \\\n",
       "201544  0.0    0.000000  0.0  0.0   6.194829  0.0  29.783459  0.0  29.06569   \n",
       "201545  0.0    0.000000  0.0  0.0   6.194829  0.0  29.783459  0.0  29.06569   \n",
       "201546  0.0    0.000000  0.0  0.0   6.194829  0.0  29.783459  0.0  29.06569   \n",
       "201547  0.0    0.000000  0.0  0.0   6.194829  0.0  29.783459  0.0  29.06569   \n",
       "201548  0.0    0.000000  0.0  0.0   6.194829  0.0  29.783459  0.0  29.06569   \n",
       "...     ...         ...  ...  ...        ...  ...        ...  ...       ...   \n",
       "201848  0.0  162.968550  0.0  0.0   0.000000  0.0   0.000000  0.0   0.00000   \n",
       "201849  0.0   98.883835  0.0  0.0   0.000000  0.0   0.000000  0.0   0.00000   \n",
       "201850  0.0    0.000000  0.0  0.0   0.000000  0.0   0.000000  0.0   0.00000   \n",
       "201851  0.0    0.000000  0.0  0.0  20.526907  0.0  49.732930  0.0  48.92910   \n",
       "201852  0.0    0.000000  0.0  0.0   0.000000  0.0   0.000000  0.0   0.00000   \n",
       "\n",
       "                9  ...       1014       1015  1016       1017  1018  1019  \\\n",
       "201544  14.480082  ...   0.000000  182.28792   0.0   6.770391   0.0   0.0   \n",
       "201545  14.480082  ...   0.000000  182.28792   0.0   6.770391   0.0   0.0   \n",
       "201546  14.480082  ...   0.000000  182.28792   0.0   6.770391   0.0   0.0   \n",
       "201547  14.480082  ...   0.000000  182.28792   0.0   6.770391   0.0   0.0   \n",
       "201548  14.480082  ...   0.000000  182.28792   0.0   6.770391   0.0   0.0   \n",
       "...           ...  ...        ...        ...   ...        ...   ...   ...   \n",
       "201848   0.000000  ...   0.000000  483.99040   0.0   0.000000   0.0   0.0   \n",
       "201849   0.000000  ...  60.541855   93.76406   0.0   0.000000   0.0   0.0   \n",
       "201850   0.000000  ...   0.000000  393.65164   0.0   0.000000   0.0   0.0   \n",
       "201851  23.647943  ...   0.000000  300.74010   0.0  14.985338   0.0   0.0   \n",
       "201852   0.000000  ...   0.000000  248.88963   0.0   0.000000   0.0   0.0   \n",
       "\n",
       "             1020        1021       1022  1023  \n",
       "201544   3.103770   22.228394  14.962168   0.0  \n",
       "201545   3.103770   22.228394  14.962168   0.0  \n",
       "201546   3.103770   22.228394  14.962168   0.0  \n",
       "201547   3.103770   22.228394  14.962168   0.0  \n",
       "201548   3.103770   22.228394  14.962168   0.0  \n",
       "...           ...         ...        ...   ...  \n",
       "201848  37.917923  194.997240   0.000000   0.0  \n",
       "201849  31.353489   95.447860   0.000000   0.0  \n",
       "201850   0.000000   47.705810   0.000000   0.0  \n",
       "201851   2.885499   10.678081  32.098557   0.0  \n",
       "201852  33.782180   21.635462   0.000000   0.0  \n",
       "\n",
       "[165 rows x 1024 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = read_features(path=embeddings, Municipality=MUNICIPALITY)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d9fb1e",
   "metadata": {},
   "source": [
    "### 2. Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffc0a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epiweek(name):\n",
    "    \n",
    "    # Get week\n",
    "    week = name.split('/')[1]\n",
    "    week = week.replace('w','')\n",
    "    week = int(week)\n",
    "    \n",
    "    # Year\n",
    "    year = name.split('/')[0]\n",
    "    year = int(year)\n",
    "    \n",
    "    epiweek = Week(year, week)\n",
    "    \n",
    "    epiweek = str(epiweek)\n",
    "    epiweek = int(epiweek)\n",
    "\n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27c01c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    if df.shape[1] > 678:\n",
    "        df = pd.concat([df[['Municipality code', 'Municipality']], df.iloc[:,-676:]], axis=1)\n",
    "        cols = df.iloc[:, 2:].columns\n",
    "        new_cols = df.iloc[:, 2:].columns.to_series().apply(get_epiweek)\n",
    "        df = df.rename(columns=dict(zip(cols, new_cols))) \n",
    "        \n",
    "    if 'Label_CSV_All_Municipality' in path:\n",
    "        # Get Columns\n",
    "        df = df[['epiweek', 'Municipality code', 'Municipality', 'final_cases_label']]\n",
    "        \n",
    "        # change epiweek format\n",
    "        df.epiweek = df.epiweek.apply(get_epiweek)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        df = df[df.duplicated(['epiweek','Municipality code','Municipality']) == False]\n",
    "        \n",
    "        # Replace Increase, decrease, stable to numerical:\n",
    "        \"\"\"\n",
    "        - Stable = 0\n",
    "        - Increased = 1 \n",
    "        - Decreased = 2\n",
    "        \"\"\"\n",
    "        df.final_cases_label = df.final_cases_label.replace({'Stable': 0, 'Increased': 1, 'Decreased': 2})\n",
    "        \n",
    "        # Create table\n",
    "        df = df.pivot(index=['Municipality code', 'Municipality'], columns='epiweek', values='final_cases_label')\n",
    "\n",
    "        # Reset Index:\n",
    "        df = df.reset_index()\n",
    "    \n",
    "    if Municipality:\n",
    "        df = df[df['Municipality'] == Municipality]\n",
    "        df.drop(columns=['Municipality code'], inplace=True)\n",
    "        df.rename(columns={'Municipality': 'Municipality Code'}, inplace=True)\n",
    "    \n",
    "        df = df.set_index('Municipality Code')\n",
    "        df = df.T\n",
    "\n",
    "        df.columns.name = None\n",
    "        df.index.name = None\n",
    "        \n",
    "        df.columns = ['Labels']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3606ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1  2\n",
       "201601  1  0  0\n",
       "201602  1  0  0\n",
       "201603  0  1  0\n",
       "201604  0  0  1\n",
       "201605  0  1  0\n",
       "...    .. .. ..\n",
       "201848  0  1  0\n",
       "201849  0  0  1\n",
       "201850  1  0  0\n",
       "201851  1  0  0\n",
       "201852  1  0  0\n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = read_labels(path=labels, Municipality=MUNICIPALITY)\n",
    "labels_df_orig = labels_df\n",
    "labels_df = pd.get_dummies(labels_df['Labels'])\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45828309",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c3854dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = labels_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a9dc0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>0.0</td>\n",
       "      <td>128.888630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.878235</td>\n",
       "      <td>52.031696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>0.0</td>\n",
       "      <td>128.888630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.878235</td>\n",
       "      <td>52.031696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>0.0</td>\n",
       "      <td>32.973410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.834430</td>\n",
       "      <td>16.112963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0.0</td>\n",
       "      <td>124.197480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.064438</td>\n",
       "      <td>17.626286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.445062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.734035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.212196</td>\n",
       "      <td>19.450012</td>\n",
       "      <td>...</td>\n",
       "      <td>8.168530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.651873</td>\n",
       "      <td>23.180506</td>\n",
       "      <td>15.441554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>0.0</td>\n",
       "      <td>162.968550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.917923</td>\n",
       "      <td>194.997240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.883835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.353489</td>\n",
       "      <td>95.447860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.705810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.526907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.732930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.929100</td>\n",
       "      <td>23.647943</td>\n",
       "      <td>...</td>\n",
       "      <td>14.985338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.885499</td>\n",
       "      <td>10.678081</td>\n",
       "      <td>32.098557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.782180</td>\n",
       "      <td>21.635462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0           1    2    3          4    5          6    7          8  \\\n",
       "201601  0.0  128.888630  0.0  0.0   0.000000  0.0   0.000000  0.0   0.000000   \n",
       "201602  0.0  128.888630  0.0  0.0   0.000000  0.0   0.000000  0.0   0.000000   \n",
       "201603  0.0   32.973410  0.0  0.0   0.000000  0.0   0.000000  0.0   0.000000   \n",
       "201604  0.0  124.197480  0.0  0.0   0.000000  0.0   0.000000  0.0   0.000000   \n",
       "201605  0.0    0.000000  0.0  0.0   7.445062  0.0  32.734035  0.0  30.212196   \n",
       "...     ...         ...  ...  ...        ...  ...        ...  ...        ...   \n",
       "201848  0.0  162.968550  0.0  0.0   0.000000  0.0   0.000000  0.0   0.000000   \n",
       "201849  0.0   98.883835  0.0  0.0   0.000000  0.0   0.000000  0.0   0.000000   \n",
       "201850  0.0    0.000000  0.0  0.0   0.000000  0.0   0.000000  0.0   0.000000   \n",
       "201851  0.0    0.000000  0.0  0.0  20.526907  0.0  49.732930  0.0  48.929100   \n",
       "201852  0.0    0.000000  0.0  0.0   0.000000  0.0   0.000000  0.0   0.000000   \n",
       "\n",
       "                9  ...       1017  1018  1019       1020        1021  \\\n",
       "201601   0.000000  ...   0.000000   0.0   0.0  64.878235   52.031696   \n",
       "201602   0.000000  ...   0.000000   0.0   0.0  64.878235   52.031696   \n",
       "201603   0.000000  ...   0.000000   0.0   0.0  12.834430   16.112963   \n",
       "201604   0.000000  ...   0.000000   0.0   0.0  27.064438   17.626286   \n",
       "201605  19.450012  ...   8.168530   0.0   0.0  12.651873   23.180506   \n",
       "...           ...  ...        ...   ...   ...        ...         ...   \n",
       "201848   0.000000  ...   0.000000   0.0   0.0  37.917923  194.997240   \n",
       "201849   0.000000  ...   0.000000   0.0   0.0  31.353489   95.447860   \n",
       "201850   0.000000  ...   0.000000   0.0   0.0   0.000000   47.705810   \n",
       "201851  23.647943  ...  14.985338   0.0   0.0   2.885499   10.678081   \n",
       "201852   0.000000  ...   0.000000   0.0   0.0  33.782180   21.635462   \n",
       "\n",
       "             1022  1023  0  1  2  \n",
       "201601   0.000000   0.0  1  0  0  \n",
       "201602   0.000000   0.0  1  0  0  \n",
       "201603   0.000000   0.0  0  1  0  \n",
       "201604   0.000000   0.0  0  0  1  \n",
       "201605  15.441554   0.0  0  1  0  \n",
       "...           ...   ... .. .. ..  \n",
       "201848   0.000000   0.0  0  1  0  \n",
       "201849   0.000000   0.0  0  0  1  \n",
       "201850   0.000000   0.0  1  0  0  \n",
       "201851  32.098557   0.0  1  0  0  \n",
       "201852   0.000000   0.0  1  0  0  \n",
       "\n",
       "[156 rows x 1027 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes based on the date values\n",
    "dengue_df = features_df.merge(labels_df, how='inner', left_index=True, right_index=True)\n",
    "dengue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3497ca81",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d41d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_percentage = 80):\n",
    "    # We need a sequence so we can't split randomly\n",
    "    # To divide into Train and test we have to calculate the train percentage of the dataset:\n",
    "    size = df.shape[0]\n",
    "    split = int(size*(train_percentage/100))\n",
    "    \n",
    "    \"\"\" Train \"\"\"\n",
    "    # We will train with 1st percentage % of data and test with the rest\n",
    "    train_df = df.iloc[:split,:] ## percentage % train\n",
    "    \n",
    "    \"\"\" Test \"\"\"\n",
    "    test_df = df.iloc[split:,:] # 100 - percentage % test\n",
    "    \n",
    "    print(f'The train shape is: {train_df.shape}')\n",
    "    print(f'The test shape is: {test_df.shape}')\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1c01fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train shape is: (124, 1027)\n",
      "The test shape is: (32, 1027)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(dengue_df, train_percentage = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19c9c47",
   "metadata": {},
   "source": [
    "### Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d01760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train data and create the scaler\n",
    "def normalize_train_features(df, feature_range=(-1, 1), n_labels=None):\n",
    "    \n",
    "    if n_labels:\n",
    "        n_features = df.shape[1] - n_labels\n",
    "    \n",
    "    scalers = {}\n",
    "    # For each column in the dataframe\n",
    "    for i, column in enumerate(df.columns):\n",
    "        if n_labels:\n",
    "            if i >= n_features:\n",
    "                break\n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Generate a new scaler\n",
    "        scaler = MinMaxScaler(feature_range=feature_range)\n",
    "        # Fit the scaler just for that column\n",
    "        scaled_column = scaler.fit_transform(values)\n",
    "        # Add the scaled column to the dataframe\n",
    "        scaled_column = np.reshape(scaled_column, len(scaled_column))\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "        # Save the scaler of the column\n",
    "        scalers['scaler_' + column] = scaler\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df, scalers\n",
    "\n",
    "\n",
    "\"\"\" If you want to use the same scaler used in train, you can use this function\"\"\"\n",
    "def normalize_test_features(df, scalers=None, n_labels=None):\n",
    "    \n",
    "    if not scalers:\n",
    "        raise TypeError(\"You should provide a list of scalers.\")\n",
    "    \n",
    "    if n_labels:\n",
    "        n_features = df.shape[1] - n_labels\n",
    "    \n",
    "    for i, column in enumerate(df.columns):\n",
    "        if n_labels:\n",
    "            if i >= n_features:\n",
    "                break\n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Take the scaler of that column\n",
    "        scaler = scalers['scaler_' + column]\n",
    "        # Scale values\n",
    "        scaled_column = scaler.transform(values)\n",
    "        scaled_column = np.reshape(scaled_column,len(scaled_column))\n",
    "        # Add the scaled values to the df\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ee4cd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "0      -1.0\n",
      "1      -1.0\n",
      "2      -1.0\n",
      "3      -1.0\n",
      "4      -1.0\n",
      "       ... \n",
      "1022   -1.0\n",
      "1023   -1.0\n",
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "Length: 1027, dtype: float64\n",
      " Max values are: \n",
      "0      -1.0\n",
      "1       1.0\n",
      "2      -1.0\n",
      "3      -1.0\n",
      "4       1.0\n",
      "       ... \n",
      "1022    1.0\n",
      "1023   -1.0\n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "Length: 1027, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.325929</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.028346</td>\n",
       "      <td>-0.400411</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.325929</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.028346</td>\n",
       "      <td>-0.400411</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.660789</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.807784</td>\n",
       "      <td>-0.814322</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.277669</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.594667</td>\n",
       "      <td>-0.796883</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.180936</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.297773</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.195502</td>\n",
       "      <td>0.466559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045788</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.810518</td>\n",
       "      <td>-0.732879</td>\n",
       "      <td>-0.032108</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1    2    3         4    5         6    7         8  \\\n",
       "201601 -1.0  0.325929 -1.0 -1.0 -1.000000 -1.0 -1.000000 -1.0 -1.000000   \n",
       "201602 -1.0  0.325929 -1.0 -1.0 -1.000000 -1.0 -1.000000 -1.0 -1.000000   \n",
       "201603 -1.0 -0.660789 -1.0 -1.0 -1.000000 -1.0 -1.000000 -1.0 -1.000000   \n",
       "201604 -1.0  0.277669 -1.0 -1.0 -1.000000 -1.0 -1.000000 -1.0 -1.000000   \n",
       "201605 -1.0 -1.000000 -1.0 -1.0 -0.180936 -1.0  0.297773 -1.0  0.195502   \n",
       "\n",
       "               9  ...      1017  1018  1019      1020      1021      1022  \\\n",
       "201601 -1.000000  ... -1.000000  -1.0  -1.0 -0.028346 -0.400411 -1.000000   \n",
       "201602 -1.000000  ... -1.000000  -1.0  -1.0 -0.028346 -0.400411 -1.000000   \n",
       "201603 -1.000000  ... -1.000000  -1.0  -1.0 -0.807784 -0.814322 -1.000000   \n",
       "201604 -1.000000  ... -1.000000  -1.0  -1.0 -0.594667 -0.796883 -1.000000   \n",
       "201605  0.466559  ... -0.045788  -1.0  -1.0 -0.810518 -0.732879 -0.032108   \n",
       "\n",
       "        1023  0  1  2  \n",
       "201601  -1.0  1  0  0  \n",
       "201602  -1.0  1  0  0  \n",
       "201603  -1.0  0  1  0  \n",
       "201604  -1.0  0  0  1  \n",
       "201605  -1.0  0  1  0  \n",
       "\n",
       "[5 rows x 1027 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_range = (-1, 1)\n",
    "\n",
    "# Scale train:\n",
    "train_df, scalers = normalize_train_features(train_df, feature_range=feature_range, n_labels=n_labels)\n",
    "\n",
    "#print(f'The scalers are: {scalers}')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "821bca80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "0      -1.0\n",
      "1      -1.0\n",
      "2      -1.0\n",
      "3      -1.0\n",
      "4      -1.0\n",
      "       ... \n",
      "1022   -1.0\n",
      "1023   -1.0\n",
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "Length: 1027, dtype: float64\n",
      " Max values are: \n",
      "0      -1.000000\n",
      "1       0.676522\n",
      "2      -1.000000\n",
      "3      -1.000000\n",
      "4       1.258256\n",
      "          ...   \n",
      "1022    1.011970\n",
      "1023   -1.000000\n",
      "0       1.000000\n",
      "1       1.000000\n",
      "2       1.000000\n",
      "Length: 1027, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201821</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.867197</td>\n",
       "      <td>-0.637486</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201822</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.806547</td>\n",
       "      <td>-0.826607</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201823</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.949499</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.934207</td>\n",
       "      <td>-0.864672</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201824</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.266053</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.986590</td>\n",
       "      <td>-0.400142</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201825</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.835434</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1    2    3    4    5    6    7    8    9  ...  1017  \\\n",
       "201821 -1.0 -1.000000 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ...  -1.0   \n",
       "201822 -1.0 -1.000000 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ...  -1.0   \n",
       "201823 -1.0 -0.949499 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ...  -1.0   \n",
       "201824 -1.0 -0.266053 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ...  -1.0   \n",
       "201825 -1.0  0.010530 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0  ...  -1.0   \n",
       "\n",
       "        1018  1019      1020      1021  1022  1023  0  1  2  \n",
       "201821  -1.0  -1.0 -0.867197 -0.637486  -1.0  -1.0  1  0  0  \n",
       "201822  -1.0  -1.0 -0.806547 -0.826607  -1.0  -1.0  0  1  0  \n",
       "201823  -1.0  -1.0 -0.934207 -0.864672  -1.0  -1.0  1  0  0  \n",
       "201824  -1.0  -1.0 -0.986590 -0.400142  -1.0  -1.0  0  1  0  \n",
       "201825  -1.0  -1.0 -0.835434 -1.000000  -1.0  -1.0  0  0  1  \n",
       "\n",
       "[5 rows x 1027 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale test:\n",
    "test_df = normalize_test_features(test_df, scalers=scalers, n_labels=n_labels)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41af5ac",
   "metadata": {},
   "source": [
    "### Prepare data for time series supervised learning (function to create sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5d1b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for time series\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa9e5cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-10)</th>\n",
       "      <th>var2(t-10)</th>\n",
       "      <th>var3(t-10)</th>\n",
       "      <th>var4(t-10)</th>\n",
       "      <th>var5(t-10)</th>\n",
       "      <th>var6(t-10)</th>\n",
       "      <th>var7(t-10)</th>\n",
       "      <th>var8(t-10)</th>\n",
       "      <th>var9(t-10)</th>\n",
       "      <th>var10(t-10)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1018(t)</th>\n",
       "      <th>var1019(t)</th>\n",
       "      <th>var1020(t)</th>\n",
       "      <th>var1021(t)</th>\n",
       "      <th>var1022(t)</th>\n",
       "      <th>var1023(t)</th>\n",
       "      <th>var1024(t)</th>\n",
       "      <th>var1025(t)</th>\n",
       "      <th>var1026(t)</th>\n",
       "      <th>var1027(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201611</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.325929</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.620904</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201612</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.325929</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.620904</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201613</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.660789</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.620904</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201614</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.277669</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.620904</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201615</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.180936</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.297773</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.195502</td>\n",
       "      <td>0.466559</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.578439</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201816</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.479237</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.995322</td>\n",
       "      <td>-0.673927</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201817</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.668477</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201818</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.312099</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.808112</td>\n",
       "      <td>-0.683993</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201819</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.882780</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.011168</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.059641</td>\n",
       "      <td>-0.009608</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.272854</td>\n",
       "      <td>-0.963339</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201820</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.508181</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.735663</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.578570</td>\n",
       "      <td>0.610416</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.769850</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 11297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        var1(t-10)  var2(t-10)  var3(t-10)  var4(t-10)  var5(t-10)  \\\n",
       "201611        -1.0    0.325929        -1.0        -1.0   -1.000000   \n",
       "201612        -1.0    0.325929        -1.0        -1.0   -1.000000   \n",
       "201613        -1.0   -0.660789        -1.0        -1.0   -1.000000   \n",
       "201614        -1.0    0.277669        -1.0        -1.0   -1.000000   \n",
       "201615        -1.0   -1.000000        -1.0        -1.0   -0.180936   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "201816        -1.0    0.479237        -1.0        -1.0   -1.000000   \n",
       "201817        -1.0    1.000000        -1.0        -1.0   -1.000000   \n",
       "201818        -1.0    0.312099        -1.0        -1.0   -1.000000   \n",
       "201819        -1.0   -1.000000        -1.0        -1.0   -0.882780   \n",
       "201820        -1.0   -1.000000        -1.0        -1.0    0.508181   \n",
       "\n",
       "        var6(t-10)  var7(t-10)  var8(t-10)  var9(t-10)  var10(t-10)  ...  \\\n",
       "201611        -1.0   -1.000000        -1.0   -1.000000    -1.000000  ...   \n",
       "201612        -1.0   -1.000000        -1.0   -1.000000    -1.000000  ...   \n",
       "201613        -1.0   -1.000000        -1.0   -1.000000    -1.000000  ...   \n",
       "201614        -1.0   -1.000000        -1.0   -1.000000    -1.000000  ...   \n",
       "201615        -1.0    0.297773        -1.0    0.195502     0.466559  ...   \n",
       "...            ...         ...         ...         ...          ...  ...   \n",
       "201816        -1.0   -1.000000        -1.0   -1.000000    -1.000000  ...   \n",
       "201817        -1.0   -1.000000        -1.0   -1.000000    -1.000000  ...   \n",
       "201818        -1.0   -1.000000        -1.0   -1.000000    -1.000000  ...   \n",
       "201819        -1.0   -0.011168        -1.0   -0.059641    -0.009608  ...   \n",
       "201820        -1.0    0.735663        -1.0    0.578570     0.610416  ...   \n",
       "\n",
       "        var1018(t)  var1019(t)  var1020(t)  var1021(t)  var1022(t)  \\\n",
       "201611        -1.0        -1.0        -1.0   -1.000000    0.620904   \n",
       "201612        -1.0        -1.0        -1.0   -1.000000    0.620904   \n",
       "201613        -1.0        -1.0        -1.0   -1.000000    0.620904   \n",
       "201614        -1.0        -1.0        -1.0   -1.000000    0.620904   \n",
       "201615        -1.0        -1.0        -1.0   -0.578439   -1.000000   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "201816        -1.0        -1.0        -1.0   -0.995322   -0.673927   \n",
       "201817        -1.0        -1.0        -1.0   -0.668477   -1.000000   \n",
       "201818        -1.0        -1.0        -1.0   -0.808112   -0.683993   \n",
       "201819        -1.0        -1.0        -1.0    0.272854   -0.963339   \n",
       "201820        -1.0        -1.0        -1.0   -1.000000   -0.769850   \n",
       "\n",
       "        var1023(t)  var1024(t)  var1025(t)  var1026(t)  var1027(t)  \n",
       "201611        -1.0        -1.0           1           0           0  \n",
       "201612        -1.0        -1.0           0           0           1  \n",
       "201613        -1.0        -1.0           0           1           0  \n",
       "201614        -1.0        -1.0           0           0           1  \n",
       "201615        -1.0        -1.0           1           0           0  \n",
       "...            ...         ...         ...         ...         ...  \n",
       "201816        -1.0        -1.0           1           0           0  \n",
       "201817        -1.0        -1.0           0           1           0  \n",
       "201818        -1.0        -1.0           1           0           0  \n",
       "201819        -1.0        -1.0           1           0           0  \n",
       "201820        -1.0        -1.0           1           0           0  \n",
       "\n",
       "[114 rows x 11297 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of window\n",
    "days = 10\n",
    "\n",
    "# frame as supervised learning\n",
    "train = series_to_supervised(train_df, n_in=days)\n",
    "test = series_to_supervised(test_df, n_in=days)\n",
    "\n",
    "DataFrame(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c9c118",
   "metadata": {},
   "source": [
    "### Features and Labels Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "392d00d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_set(timeseries_data, original_df, n_labels):\n",
    "    \n",
    "    \"\"\" Features \"\"\"\n",
    "    # We define the number of features as (features and labels)\n",
    "    n_features = original_df.shape[1]\n",
    "\n",
    "    # The features to train the model will be all except the values of the actual week \n",
    "    # We can't use other variables in week t because whe need to resample a a 3D Array\n",
    "    features_set = DataFrame(timeseries_data.values[:,:-n_features])\n",
    "    # Convert pandas data frame to np.array to reshape as 3D Array\n",
    "    features_set = features_set.to_numpy()\n",
    "    print(f'The shape of the features is {features_set.shape}')\n",
    "    \n",
    "    \"\"\" Labels \"\"\"\n",
    "    # We will use labels in last week \n",
    "    labels_set = DataFrame(timeseries_data.values[:,-n_labels:])\n",
    "    # Convert pandas data frame to np.array\n",
    "    labels_set = labels_set.to_numpy()\n",
    "    print(f'The shape of the labels is {labels_set.shape}')\n",
    "    \n",
    "    return features_set, labels_set, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "814d00c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "The shape of the features is (114, 10270)\n",
      "The shape of the labels is (114, 3)\n",
      "Test:\n",
      "The shape of the features is (22, 10270)\n",
      "The shape of the labels is (22, 3)\n"
     ]
    }
   ],
   "source": [
    "# Train features and labels set\n",
    "print('Train:')\n",
    "train_X, train_y, n_features = features_labels_set(timeseries_data=train, original_df=dengue_df, n_labels=n_labels)\n",
    "\n",
    "# Test features and labels set\n",
    "print('Test:')\n",
    "test_X, test_y, n_features = features_labels_set(timeseries_data=test, original_df=dengue_df, n_labels=n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275c7a2e",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "584a966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tensor(train_X, test_X, n_features):\n",
    "    print('The initial shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], days, n_features))\n",
    "    test_X = test_X.reshape((test_X.shape[0], days, n_features))\n",
    "    \n",
    "    print('-----------------------')\n",
    "    print('The Final shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    return train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3197b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial shapes are:\n",
      "The train shape is (114, 10270)\n",
      "The test shape is (22, 10270)\n",
      "-----------------------\n",
      "The Final shapes are:\n",
      "The train shape is (114, 10, 1027)\n",
      "The test shape is (22, 10, 1027)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X, test_X = reshape_tensor(train_X, test_X, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01047b03",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d9740ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "#tf.random.set_seed(0)\n",
    "\n",
    "def create_model():\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(120, dropout=0.1, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "    model.add(LSTM(240, dropout=0.1, input_shape=(train_X.shape[1], 120)))\n",
    "    model.add(Dense(60))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # Compile the model:\n",
    "    opt = keras.optimizers.Adam()\n",
    "    metrics = [\n",
    "        tf.keras.metrics.AUC(name='auc', multi_label=False), #num_labels=3),\n",
    "        tf.keras.metrics.CategoricalAccuracy(name='acc'),\n",
    "        tf.keras.metrics.CategoricalCrossentropy(name='entropy')\n",
    "    ]\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ab59a2",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "383a62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# EarlyStopping:\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "807435ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros: 104, ones: 23, twos: 29, total: 156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 1.5, 1: 6.782608695652174, 2: 5.379310344827586}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Imbalanced data\n",
    "n_zeros = (labels_df_orig.to_numpy() == 0).sum()\n",
    "n_ones = (labels_df_orig.to_numpy() == 1).sum()\n",
    "n_twos = (labels_df_orig.to_numpy() == 2).sum()\n",
    "n_total = n_zeros + n_ones + n_twos\n",
    "\n",
    "weights = {0: n_total/n_zeros, 1: n_total/n_ones, 2: n_total/n_twos}\n",
    "print(f'zeros: {n_zeros}, ones: {n_ones}, twos: {n_twos}, total: {n_total}')\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d20873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "def train_model(model, monitor, weights, plot=None, epochs=20):\n",
    "    if monitor and weights:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor], class_weight=weights)\n",
    "    elif monitor:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor])\n",
    "    elif weights:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, class_weight=weights)\n",
    "    else:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    \n",
    "    if plot:\n",
    "        # plot history\n",
    "        plt.plot(history.history['loss'], label='train')\n",
    "        plt.plot(history.history['val_loss'], label='validation')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf1a750",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9163a34",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3aa018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also evaluate or predict on a dataset.\n",
    "def evaluate(model, verbose = None):\n",
    "    if verbose:\n",
    "        print('Evaluate: ')\n",
    "    result = model.evaluate(test_X, test_y)\n",
    "    stored_results = {}\n",
    "    for i, metric in enumerate(model.metrics_names):\n",
    "        stored_results[metric] = result[i]\n",
    "        if verbose:\n",
    "            print(f'{metric}: {result[i]}')\n",
    "    return stored_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b3ab3e",
   "metadata": {},
   "source": [
    "# Calculate Mean and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6322e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(weights):\n",
    "    \n",
    "    metrics = {\n",
    "        \"auc\": [],\n",
    "        \"acc\": [],\n",
    "        \"entropy\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(5):\n",
    "        model = create_model()\n",
    "        train_model(model=model, monitor=monitor, weights=weights)\n",
    "        stored_results = evaluate(model=model)\n",
    "        \n",
    "        for key in metrics.keys():\n",
    "            metrics[key].append(stored_results[key])\n",
    "            \n",
    "    for key in metrics.keys():\n",
    "        results = metrics[key]\n",
    "        print(key, f\": average={np.average(results):.3f}, std={np.std(results):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb49e36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 1.0155 - auc: 0.7452 - acc: 0.5965 - entropy: 1.0155 - val_loss: 0.7166 - val_auc: 0.8678 - val_acc: 0.8182 - val_entropy: 0.7166\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 1.2054 - auc: 0.6686 - acc: 0.6667 - entropy: 1.2054 - val_loss: 0.7180 - val_auc: 0.8626 - val_acc: 0.8182 - val_entropy: 0.7180\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.8606 - auc: 0.7864 - acc: 0.6667 - entropy: 0.8606 - val_loss: 0.6270 - val_auc: 0.8580 - val_acc: 0.8182 - val_entropy: 0.6270\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.8965 - auc: 0.7349 - acc: 0.6667 - entropy: 0.8965 - val_loss: 0.6172 - val_auc: 0.8574 - val_acc: 0.8182 - val_entropy: 0.6172\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.8942 - auc: 0.6789 - acc: 0.6667 - entropy: 0.8942 - val_loss: 0.6357 - val_auc: 0.8853 - val_acc: 0.8182 - val_entropy: 0.6357\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.8762 - auc: 0.7079 - acc: 0.6667 - entropy: 0.8762 - val_loss: 0.6309 - val_auc: 0.8926 - val_acc: 0.8182 - val_entropy: 0.6309\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.8705 - auc: 0.7509 - acc: 0.6667 - entropy: 0.8705 - val_loss: 0.6248 - val_auc: 0.8874 - val_acc: 0.8182 - val_entropy: 0.6248\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.8752 - auc: 0.7419 - acc: 0.6667 - entropy: 0.8752 - val_loss: 0.6232 - val_auc: 0.8998 - val_acc: 0.8182 - val_entropy: 0.6232\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.8678 - auc: 0.7652 - acc: 0.6667 - entropy: 0.8678 - val_loss: 0.6213 - val_auc: 0.8889 - val_acc: 0.8182 - val_entropy: 0.6213\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.8647 - auc: 0.7631 - acc: 0.6667 - entropy: 0.8647 - val_loss: 0.6183 - val_auc: 0.8900 - val_acc: 0.8182 - val_entropy: 0.6183\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.8594 - auc: 0.7772 - acc: 0.6667 - entropy: 0.8594 - val_loss: 0.6137 - val_auc: 0.8946 - val_acc: 0.8182 - val_entropy: 0.6137\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.8553 - auc: 0.7835 - acc: 0.6667 - entropy: 0.8553 - val_loss: 0.6064 - val_auc: 0.8946 - val_acc: 0.8182 - val_entropy: 0.6064\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.8586 - auc: 0.7745 - acc: 0.6667 - entropy: 0.8586 - val_loss: 0.6016 - val_auc: 0.9024 - val_acc: 0.8182 - val_entropy: 0.6016\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.8541 - auc: 0.7796 - acc: 0.6667 - entropy: 0.8541 - val_loss: 0.5926 - val_auc: 0.9039 - val_acc: 0.8182 - val_entropy: 0.5926\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.8545 - auc: 0.7794 - acc: 0.6667 - entropy: 0.8545 - val_loss: 0.5911 - val_auc: 0.9029 - val_acc: 0.8182 - val_entropy: 0.5911\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.8428 - auc: 0.7926 - acc: 0.6667 - entropy: 0.8428 - val_loss: 0.5871 - val_auc: 0.9050 - val_acc: 0.8182 - val_entropy: 0.5871\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.8514 - auc: 0.7859 - acc: 0.6667 - entropy: 0.8514 - val_loss: 0.5913 - val_auc: 0.9060 - val_acc: 0.8182 - val_entropy: 0.5913\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.8299 - auc: 0.8029 - acc: 0.6667 - entropy: 0.8299 - val_loss: 0.5816 - val_auc: 0.9050 - val_acc: 0.8182 - val_entropy: 0.5816\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.8307 - auc: 0.8014 - acc: 0.6667 - entropy: 0.8307 - val_loss: 0.5828 - val_auc: 0.9060 - val_acc: 0.8182 - val_entropy: 0.5828\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.8245 - auc: 0.8042 - acc: 0.6667 - entropy: 0.8245 - val_loss: 0.5812 - val_auc: 0.9060 - val_acc: 0.8182 - val_entropy: 0.5812\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5812 - auc: 0.9060 - acc: 0.8182 - entropy: 0.5812\n",
      "Epoch 1/20\n",
      "8/8 - 2s - loss: 1.0912 - auc: 0.7203 - acc: 0.5965 - entropy: 1.0912 - val_loss: 0.7100 - val_auc: 0.8605 - val_acc: 0.8182 - val_entropy: 0.7100\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 1.2018 - auc: 0.6686 - acc: 0.6667 - entropy: 1.2018 - val_loss: 0.7286 - val_auc: 0.8595 - val_acc: 0.8182 - val_entropy: 0.7286\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.8578 - auc: 0.7935 - acc: 0.6667 - entropy: 0.8578 - val_loss: 0.6182 - val_auc: 0.8626 - val_acc: 0.8182 - val_entropy: 0.6182\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.8967 - auc: 0.7183 - acc: 0.6667 - entropy: 0.8967 - val_loss: 0.6153 - val_auc: 0.8332 - val_acc: 0.8182 - val_entropy: 0.6153\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.8958 - auc: 0.6793 - acc: 0.6667 - entropy: 0.8958 - val_loss: 0.6361 - val_auc: 0.8569 - val_acc: 0.8182 - val_entropy: 0.6361\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.8822 - auc: 0.7105 - acc: 0.6667 - entropy: 0.8822 - val_loss: 0.6411 - val_auc: 0.8549 - val_acc: 0.8182 - val_entropy: 0.6411\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.8660 - auc: 0.7612 - acc: 0.6667 - entropy: 0.8660 - val_loss: 0.6311 - val_auc: 0.8502 - val_acc: 0.8182 - val_entropy: 0.6311\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.8806 - auc: 0.7155 - acc: 0.6667 - entropy: 0.8806 - val_loss: 0.6293 - val_auc: 0.8569 - val_acc: 0.8182 - val_entropy: 0.6293\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.8794 - auc: 0.7155 - acc: 0.6667 - entropy: 0.8794 - val_loss: 0.6336 - val_auc: 0.8559 - val_acc: 0.8182 - val_entropy: 0.6336\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.8778 - auc: 0.7253 - acc: 0.6667 - entropy: 0.8778 - val_loss: 0.6363 - val_auc: 0.8471 - val_acc: 0.8182 - val_entropy: 0.6363\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.8749 - auc: 0.7330 - acc: 0.6667 - entropy: 0.8749 - val_loss: 0.6361 - val_auc: 0.8590 - val_acc: 0.8182 - val_entropy: 0.6361\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.8725 - auc: 0.7405 - acc: 0.6667 - entropy: 0.8725 - val_loss: 0.6347 - val_auc: 0.8559 - val_acc: 0.8182 - val_entropy: 0.6347\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.8745 - auc: 0.7332 - acc: 0.6667 - entropy: 0.8745 - val_loss: 0.6346 - val_auc: 0.8590 - val_acc: 0.8182 - val_entropy: 0.6346\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.8734 - auc: 0.7334 - acc: 0.6667 - entropy: 0.8734 - val_loss: 0.6359 - val_auc: 0.8590 - val_acc: 0.8182 - val_entropy: 0.6359\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.8707 - auc: 0.7377 - acc: 0.6667 - entropy: 0.8707 - val_loss: 0.6347 - val_auc: 0.8559 - val_acc: 0.8182 - val_entropy: 0.6347\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.8656 - auc: 0.7482 - acc: 0.6667 - entropy: 0.8656 - val_loss: 0.6297 - val_auc: 0.8621 - val_acc: 0.8182 - val_entropy: 0.6297\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.8649 - auc: 0.7585 - acc: 0.6667 - entropy: 0.8649 - val_loss: 0.6232 - val_auc: 0.8735 - val_acc: 0.8182 - val_entropy: 0.6232\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.8643 - auc: 0.7669 - acc: 0.6667 - entropy: 0.8643 - val_loss: 0.6114 - val_auc: 0.8791 - val_acc: 0.8182 - val_entropy: 0.6114\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.8671 - auc: 0.7611 - acc: 0.6667 - entropy: 0.8671 - val_loss: 0.6271 - val_auc: 0.8750 - val_acc: 0.8182 - val_entropy: 0.6271\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.8507 - auc: 0.7861 - acc: 0.6667 - entropy: 0.8507 - val_loss: 0.6169 - val_auc: 0.8750 - val_acc: 0.8182 - val_entropy: 0.6169\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6169 - auc: 0.8750 - acc: 0.8182 - entropy: 0.6169\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 1.0651 - auc: 0.7372 - acc: 0.5965 - entropy: 1.0651 - val_loss: 0.6926 - val_auc: 0.8595 - val_acc: 0.8182 - val_entropy: 0.6926\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 1.1897 - auc: 0.6710 - acc: 0.6667 - entropy: 1.1897 - val_loss: 0.7083 - val_auc: 0.8611 - val_acc: 0.8182 - val_entropy: 0.7083\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.8445 - auc: 0.8087 - acc: 0.6667 - entropy: 0.8445 - val_loss: 0.6094 - val_auc: 0.8507 - val_acc: 0.8182 - val_entropy: 0.6094\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.9089 - auc: 0.7103 - acc: 0.6667 - entropy: 0.9089 - val_loss: 0.6192 - val_auc: 0.8678 - val_acc: 0.8182 - val_entropy: 0.6192\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.8964 - auc: 0.6918 - acc: 0.6667 - entropy: 0.8964 - val_loss: 0.6433 - val_auc: 0.8807 - val_acc: 0.8182 - val_entropy: 0.6433\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.8724 - auc: 0.7311 - acc: 0.6667 - entropy: 0.8724 - val_loss: 0.6323 - val_auc: 0.8833 - val_acc: 0.8182 - val_entropy: 0.6323\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.8709 - auc: 0.7437 - acc: 0.6667 - entropy: 0.8709 - val_loss: 0.6205 - val_auc: 0.8874 - val_acc: 0.8182 - val_entropy: 0.6205\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.8781 - auc: 0.7333 - acc: 0.6667 - entropy: 0.8781 - val_loss: 0.6217 - val_auc: 0.8869 - val_acc: 0.8182 - val_entropy: 0.6217\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.8744 - auc: 0.7376 - acc: 0.6667 - entropy: 0.8744 - val_loss: 0.6263 - val_auc: 0.8879 - val_acc: 0.8182 - val_entropy: 0.6263\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.8682 - auc: 0.7582 - acc: 0.6667 - entropy: 0.8682 - val_loss: 0.6218 - val_auc: 0.8853 - val_acc: 0.8182 - val_entropy: 0.6218\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.8646 - auc: 0.7666 - acc: 0.6667 - entropy: 0.8646 - val_loss: 0.6140 - val_auc: 0.8931 - val_acc: 0.8182 - val_entropy: 0.6140\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.8643 - auc: 0.7685 - acc: 0.6667 - entropy: 0.8643 - val_loss: 0.6113 - val_auc: 0.8905 - val_acc: 0.8182 - val_entropy: 0.6113\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.8563 - auc: 0.7772 - acc: 0.6667 - entropy: 0.8563 - val_loss: 0.5903 - val_auc: 0.8941 - val_acc: 0.8182 - val_entropy: 0.5903\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.8763 - auc: 0.7565 - acc: 0.6667 - entropy: 0.8763 - val_loss: 0.6091 - val_auc: 0.9008 - val_acc: 0.8182 - val_entropy: 0.6091\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.8526 - auc: 0.7901 - acc: 0.6667 - entropy: 0.8526 - val_loss: 0.5943 - val_auc: 0.9003 - val_acc: 0.8182 - val_entropy: 0.5943\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.8610 - auc: 0.7800 - acc: 0.6667 - entropy: 0.8610 - val_loss: 0.5914 - val_auc: 0.9070 - val_acc: 0.8182 - val_entropy: 0.5914\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.8526 - auc: 0.7888 - acc: 0.6667 - entropy: 0.8526 - val_loss: 0.5853 - val_auc: 0.9070 - val_acc: 0.8182 - val_entropy: 0.5853\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.8486 - auc: 0.7879 - acc: 0.6667 - entropy: 0.8486 - val_loss: 0.5831 - val_auc: 0.9091 - val_acc: 0.8182 - val_entropy: 0.5831\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.8443 - auc: 0.7911 - acc: 0.6667 - entropy: 0.8443 - val_loss: 0.5805 - val_auc: 0.9101 - val_acc: 0.8182 - val_entropy: 0.5805\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.8424 - auc: 0.7923 - acc: 0.6667 - entropy: 0.8424 - val_loss: 0.5830 - val_auc: 0.9117 - val_acc: 0.8182 - val_entropy: 0.5830\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5830 - auc: 0.9117 - acc: 0.8182 - entropy: 0.5830\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 0.9404 - auc: 0.7517 - acc: 0.6053 - entropy: 0.9404 - val_loss: 0.6678 - val_auc: 0.8574 - val_acc: 0.8182 - val_entropy: 0.6678\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 1.1154 - auc: 0.6707 - acc: 0.6667 - entropy: 1.1154 - val_loss: 0.7108 - val_auc: 0.8621 - val_acc: 0.8182 - val_entropy: 0.7108\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.8632 - auc: 0.7807 - acc: 0.6667 - entropy: 0.8632 - val_loss: 0.6275 - val_auc: 0.8425 - val_acc: 0.8182 - val_entropy: 0.6275\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.8809 - auc: 0.7327 - acc: 0.6667 - entropy: 0.8809 - val_loss: 0.6155 - val_auc: 0.8425 - val_acc: 0.8182 - val_entropy: 0.6155\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.8980 - auc: 0.6903 - acc: 0.6667 - entropy: 0.8980 - val_loss: 0.6357 - val_auc: 0.8518 - val_acc: 0.8182 - val_entropy: 0.6357\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.8808 - auc: 0.7052 - acc: 0.6667 - entropy: 0.8808 - val_loss: 0.6410 - val_auc: 0.8445 - val_acc: 0.8182 - val_entropy: 0.6410\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.8712 - auc: 0.7431 - acc: 0.6667 - entropy: 0.8712 - val_loss: 0.6320 - val_auc: 0.8471 - val_acc: 0.8182 - val_entropy: 0.6320\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.8769 - auc: 0.7269 - acc: 0.6667 - entropy: 0.8769 - val_loss: 0.6312 - val_auc: 0.8487 - val_acc: 0.8182 - val_entropy: 0.6312\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.8755 - auc: 0.7290 - acc: 0.6667 - entropy: 0.8755 - val_loss: 0.6341 - val_auc: 0.8497 - val_acc: 0.8182 - val_entropy: 0.6341\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.8700 - auc: 0.7489 - acc: 0.6667 - entropy: 0.8700 - val_loss: 0.6322 - val_auc: 0.8569 - val_acc: 0.8182 - val_entropy: 0.6322\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.8691 - auc: 0.7515 - acc: 0.6667 - entropy: 0.8691 - val_loss: 0.6324 - val_auc: 0.8580 - val_acc: 0.8182 - val_entropy: 0.6324\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.8675 - auc: 0.7504 - acc: 0.6667 - entropy: 0.8675 - val_loss: 0.6302 - val_auc: 0.8631 - val_acc: 0.8182 - val_entropy: 0.6302\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.8629 - auc: 0.7605 - acc: 0.6667 - entropy: 0.8629 - val_loss: 0.6265 - val_auc: 0.8642 - val_acc: 0.8182 - val_entropy: 0.6265\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.8558 - auc: 0.7728 - acc: 0.6667 - entropy: 0.8558 - val_loss: 0.6155 - val_auc: 0.8781 - val_acc: 0.8182 - val_entropy: 0.6155\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.8448 - auc: 0.7935 - acc: 0.6667 - entropy: 0.8448 - val_loss: 0.6063 - val_auc: 0.8853 - val_acc: 0.8182 - val_entropy: 0.6063\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.8461 - auc: 0.7914 - acc: 0.6667 - entropy: 0.8461 - val_loss: 0.6018 - val_auc: 0.8910 - val_acc: 0.8182 - val_entropy: 0.6018\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.8303 - auc: 0.8003 - acc: 0.6667 - entropy: 0.8303 - val_loss: 0.6026 - val_auc: 0.8951 - val_acc: 0.8182 - val_entropy: 0.6026\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.8287 - auc: 0.8025 - acc: 0.6667 - entropy: 0.8287 - val_loss: 0.5998 - val_auc: 0.8926 - val_acc: 0.8182 - val_entropy: 0.5998\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.8334 - auc: 0.7972 - acc: 0.6667 - entropy: 0.8334 - val_loss: 0.6064 - val_auc: 0.8977 - val_acc: 0.8182 - val_entropy: 0.6064\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.8310 - auc: 0.8008 - acc: 0.6667 - entropy: 0.8310 - val_loss: 0.6025 - val_auc: 0.8982 - val_acc: 0.8182 - val_entropy: 0.6025\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6025 - auc: 0.8982 - acc: 0.8182 - entropy: 0.6025\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 1.0259 - auc: 0.7081 - acc: 0.5702 - entropy: 1.0259 - val_loss: 0.6781 - val_auc: 0.8559 - val_acc: 0.8182 - val_entropy: 0.6781\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 1.1327 - auc: 0.6675 - acc: 0.6667 - entropy: 1.1327 - val_loss: 0.6822 - val_auc: 0.8709 - val_acc: 0.8182 - val_entropy: 0.6822\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.8698 - auc: 0.7500 - acc: 0.6667 - entropy: 0.8698 - val_loss: 0.6256 - val_auc: 0.8616 - val_acc: 0.8182 - val_entropy: 0.6256\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.8776 - auc: 0.7281 - acc: 0.6667 - entropy: 0.8776 - val_loss: 0.6161 - val_auc: 0.8533 - val_acc: 0.8182 - val_entropy: 0.6161\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.8934 - auc: 0.7010 - acc: 0.6667 - entropy: 0.8934 - val_loss: 0.6316 - val_auc: 0.8657 - val_acc: 0.8182 - val_entropy: 0.6316\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.8799 - auc: 0.7159 - acc: 0.6667 - entropy: 0.8799 - val_loss: 0.6337 - val_auc: 0.8667 - val_acc: 0.8182 - val_entropy: 0.6337\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.8756 - auc: 0.7275 - acc: 0.6667 - entropy: 0.8756 - val_loss: 0.6235 - val_auc: 0.8611 - val_acc: 0.8182 - val_entropy: 0.6235\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.8770 - auc: 0.7324 - acc: 0.6667 - entropy: 0.8770 - val_loss: 0.6230 - val_auc: 0.8724 - val_acc: 0.8182 - val_entropy: 0.6230\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.8667 - auc: 0.7576 - acc: 0.6667 - entropy: 0.8667 - val_loss: 0.6106 - val_auc: 0.8874 - val_acc: 0.8182 - val_entropy: 0.6106\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.8634 - auc: 0.7692 - acc: 0.6667 - entropy: 0.8634 - val_loss: 0.6047 - val_auc: 0.8967 - val_acc: 0.8182 - val_entropy: 0.6047\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.8601 - auc: 0.7784 - acc: 0.6667 - entropy: 0.8601 - val_loss: 0.5954 - val_auc: 0.9060 - val_acc: 0.8182 - val_entropy: 0.5954\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.8549 - auc: 0.7823 - acc: 0.6667 - entropy: 0.8549 - val_loss: 0.5947 - val_auc: 0.9044 - val_acc: 0.8182 - val_entropy: 0.5947\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.8428 - auc: 0.7897 - acc: 0.6667 - entropy: 0.8428 - val_loss: 0.5864 - val_auc: 0.9075 - val_acc: 0.8182 - val_entropy: 0.5864\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.8396 - auc: 0.7944 - acc: 0.6667 - entropy: 0.8396 - val_loss: 0.5757 - val_auc: 0.9070 - val_acc: 0.8182 - val_entropy: 0.5757\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.8528 - auc: 0.7870 - acc: 0.6667 - entropy: 0.8528 - val_loss: 0.5994 - val_auc: 0.9117 - val_acc: 0.8182 - val_entropy: 0.5994\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.8297 - auc: 0.8028 - acc: 0.6667 - entropy: 0.8297 - val_loss: 0.5817 - val_auc: 0.9065 - val_acc: 0.8182 - val_entropy: 0.5817\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.8305 - auc: 0.8013 - acc: 0.6754 - entropy: 0.8305 - val_loss: 0.5759 - val_auc: 0.9060 - val_acc: 0.8182 - val_entropy: 0.5759\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.8360 - auc: 0.8016 - acc: 0.6667 - entropy: 0.8360 - val_loss: 0.5859 - val_auc: 0.9029 - val_acc: 0.8182 - val_entropy: 0.5859\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.8081 - auc: 0.8162 - acc: 0.6754 - entropy: 0.8081 - val_loss: 0.5774 - val_auc: 0.9029 - val_acc: 0.8182 - val_entropy: 0.5774\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.8044 - auc: 0.8160 - acc: 0.6754 - entropy: 0.8044 - val_loss: 0.5772 - val_auc: 0.9060 - val_acc: 0.8182 - val_entropy: 0.5772\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5772 - auc: 0.9060 - acc: 0.8182 - entropy: 0.5772\n",
      "auc : average=0.899, std=0.013\n",
      "acc : average=0.818, std=0.000\n",
      "entropy : average=0.592, std=0.015\n"
     ]
    }
   ],
   "source": [
    "calculate_mean_std(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbac38cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 - 2s - loss: 4.0411 - auc: 0.5148 - acc: 0.3684 - entropy: 1.5389 - val_loss: 0.6097 - val_auc: 0.8755 - val_acc: 0.8182 - val_entropy: 0.6097\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 4.7786 - auc: 0.4866 - acc: 0.2281 - entropy: 1.3298 - val_loss: 1.3445 - val_auc: 0.1544 - val_acc: 0.0909 - val_entropy: 1.3445\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 3.2772 - auc: 0.3429 - acc: 0.1754 - entropy: 1.1896 - val_loss: 1.0117 - val_auc: 0.5067 - val_acc: 0.0909 - val_entropy: 1.0117\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 3.3584 - auc: 0.7278 - acc: 0.6491 - entropy: 1.0380 - val_loss: 0.9382 - val_auc: 0.8688 - val_acc: 0.8182 - val_entropy: 0.9382\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 3.3807 - auc: 0.7142 - acc: 0.6579 - entropy: 1.0369 - val_loss: 0.9925 - val_auc: 0.8724 - val_acc: 0.8182 - val_entropy: 0.9925\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 3.3297 - auc: 0.7332 - acc: 0.6667 - entropy: 1.0530 - val_loss: 1.0104 - val_auc: 0.8678 - val_acc: 0.8182 - val_entropy: 1.0104\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 3.3119 - auc: 0.7264 - acc: 0.6316 - entropy: 1.0590 - val_loss: 1.0079 - val_auc: 0.8688 - val_acc: 0.8182 - val_entropy: 1.0079\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 3.3025 - auc: 0.7409 - acc: 0.6579 - entropy: 1.0532 - val_loss: 0.9755 - val_auc: 0.8895 - val_acc: 0.8182 - val_entropy: 0.9755\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 3.3052 - auc: 0.7460 - acc: 0.6140 - entropy: 1.0451 - val_loss: 0.9853 - val_auc: 0.9112 - val_acc: 0.8182 - val_entropy: 0.9853\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 3.2867 - auc: 0.7412 - acc: 0.5789 - entropy: 1.0468 - val_loss: 0.9660 - val_auc: 0.9039 - val_acc: 0.7727 - val_entropy: 0.9660\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 3.2871 - auc: 0.7598 - acc: 0.5965 - entropy: 1.0263 - val_loss: 0.9524 - val_auc: 0.9044 - val_acc: 0.7727 - val_entropy: 0.9524\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 3.2722 - auc: 0.7514 - acc: 0.5789 - entropy: 1.0249 - val_loss: 0.9550 - val_auc: 0.8931 - val_acc: 0.7727 - val_entropy: 0.9550\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 3.2736 - auc: 0.7027 - acc: 0.5702 - entropy: 1.0322 - val_loss: 0.9497 - val_auc: 0.8667 - val_acc: 0.6818 - val_entropy: 0.9497\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 3.2199 - auc: 0.6798 - acc: 0.5351 - entropy: 1.0369 - val_loss: 0.9077 - val_auc: 0.8771 - val_acc: 0.6818 - val_entropy: 0.9077\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 3.2325 - auc: 0.7083 - acc: 0.5175 - entropy: 1.0090 - val_loss: 0.9112 - val_auc: 0.8538 - val_acc: 0.6818 - val_entropy: 0.9112\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 3.2107 - auc: 0.6825 - acc: 0.5088 - entropy: 1.0131 - val_loss: 0.9286 - val_auc: 0.8006 - val_acc: 0.6364 - val_entropy: 0.9286\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 3.1795 - auc: 0.6685 - acc: 0.5175 - entropy: 1.0204 - val_loss: 0.9148 - val_auc: 0.8037 - val_acc: 0.6364 - val_entropy: 0.9148\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 3.1720 - auc: 0.6726 - acc: 0.5175 - entropy: 1.0139 - val_loss: 0.8877 - val_auc: 0.8301 - val_acc: 0.6818 - val_entropy: 0.8877\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 3.1871 - auc: 0.6673 - acc: 0.5263 - entropy: 1.0109 - val_loss: 0.8976 - val_auc: 0.8053 - val_acc: 0.6364 - val_entropy: 0.8976\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 3.1888 - auc: 0.6537 - acc: 0.5175 - entropy: 1.0237 - val_loss: 0.8899 - val_auc: 0.8032 - val_acc: 0.6364 - val_entropy: 0.8899\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8899 - auc: 0.8032 - acc: 0.6364 - entropy: 0.8899\n",
      "Epoch 1/20\n",
      "8/8 - 2s - loss: 3.9111 - auc: 0.5305 - acc: 0.3596 - entropy: 1.4249 - val_loss: 0.6263 - val_auc: 0.8404 - val_acc: 0.8182 - val_entropy: 0.6263\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 4.7747 - auc: 0.4999 - acc: 0.3333 - entropy: 1.2734 - val_loss: 1.3382 - val_auc: 0.1389 - val_acc: 0.0909 - val_entropy: 1.3382\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 3.3016 - auc: 0.2809 - acc: 0.1491 - entropy: 1.2116 - val_loss: 1.0026 - val_auc: 0.8667 - val_acc: 0.8182 - val_entropy: 1.0026\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 3.3343 - auc: 0.7315 - acc: 0.6667 - entropy: 1.0180 - val_loss: 0.9086 - val_auc: 0.8399 - val_acc: 0.8182 - val_entropy: 0.9086\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 3.3979 - auc: 0.7002 - acc: 0.6667 - entropy: 1.0269 - val_loss: 0.9933 - val_auc: 0.8425 - val_acc: 0.8182 - val_entropy: 0.9933\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 3.3493 - auc: 0.6839 - acc: 0.6754 - entropy: 1.0736 - val_loss: 1.0386 - val_auc: 0.8471 - val_acc: 0.8182 - val_entropy: 1.0386\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 3.3259 - auc: 0.6843 - acc: 0.6316 - entropy: 1.0803 - val_loss: 1.0278 - val_auc: 0.8301 - val_acc: 0.8182 - val_entropy: 1.0278\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 3.3135 - auc: 0.7246 - acc: 0.6579 - entropy: 1.0626 - val_loss: 1.0048 - val_auc: 0.8383 - val_acc: 0.8182 - val_entropy: 1.0048\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 3.3210 - auc: 0.7139 - acc: 0.6579 - entropy: 1.0550 - val_loss: 1.0025 - val_auc: 0.8419 - val_acc: 0.8182 - val_entropy: 1.0025\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 3.3336 - auc: 0.7015 - acc: 0.6667 - entropy: 1.0591 - val_loss: 1.0093 - val_auc: 0.8440 - val_acc: 0.8182 - val_entropy: 1.0093\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 3.3202 - auc: 0.7122 - acc: 0.6404 - entropy: 1.0590 - val_loss: 1.0113 - val_auc: 0.8425 - val_acc: 0.8182 - val_entropy: 1.0113\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 3.3073 - auc: 0.7290 - acc: 0.6316 - entropy: 1.0561 - val_loss: 1.0116 - val_auc: 0.8440 - val_acc: 0.8182 - val_entropy: 1.0116\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 3.3126 - auc: 0.7246 - acc: 0.6140 - entropy: 1.0556 - val_loss: 1.0109 - val_auc: 0.8373 - val_acc: 0.8182 - val_entropy: 1.0109\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 3.2997 - auc: 0.7216 - acc: 0.5789 - entropy: 1.0526 - val_loss: 1.0103 - val_auc: 0.8383 - val_acc: 0.8182 - val_entropy: 1.0103\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 3.2764 - auc: 0.7317 - acc: 0.6140 - entropy: 1.0477 - val_loss: 1.0093 - val_auc: 0.8425 - val_acc: 0.8182 - val_entropy: 1.0093\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 3.2746 - auc: 0.7034 - acc: 0.5351 - entropy: 1.0450 - val_loss: 1.0023 - val_auc: 0.8326 - val_acc: 0.8182 - val_entropy: 1.0023\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 3.2453 - auc: 0.6887 - acc: 0.4737 - entropy: 1.0417 - val_loss: 1.0092 - val_auc: 0.8125 - val_acc: 0.7273 - val_entropy: 1.0092\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 3.2265 - auc: 0.6691 - acc: 0.4386 - entropy: 1.0334 - val_loss: 0.9667 - val_auc: 0.8378 - val_acc: 0.7727 - val_entropy: 0.9667\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 3.2305 - auc: 0.6443 - acc: 0.3947 - entropy: 1.0392 - val_loss: 0.9761 - val_auc: 0.7831 - val_acc: 0.6364 - val_entropy: 0.9761\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 3.1819 - auc: 0.7191 - acc: 0.5088 - entropy: 1.0064 - val_loss: 0.9159 - val_auc: 0.8264 - val_acc: 0.6818 - val_entropy: 0.9159\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9159 - auc: 0.8264 - acc: 0.6818 - entropy: 0.9159\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 4.3594 - auc: 0.4158 - acc: 0.2719 - entropy: 1.7368 - val_loss: 0.6178 - val_auc: 0.8497 - val_acc: 0.8182 - val_entropy: 0.6178\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 4.7889 - auc: 0.5752 - acc: 0.4211 - entropy: 1.2092 - val_loss: 1.2730 - val_auc: 0.1348 - val_acc: 0.0455 - val_entropy: 1.2730\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 3.3575 - auc: 0.2365 - acc: 0.1491 - entropy: 1.2415 - val_loss: 1.1188 - val_auc: 0.4737 - val_acc: 0.0909 - val_entropy: 1.1188\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 3.2845 - auc: 0.6813 - acc: 0.5439 - entropy: 1.0689 - val_loss: 0.9435 - val_auc: 0.8450 - val_acc: 0.8182 - val_entropy: 0.9435\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 3.3564 - auc: 0.7300 - acc: 0.6667 - entropy: 1.0123 - val_loss: 0.9444 - val_auc: 0.8471 - val_acc: 0.8182 - val_entropy: 0.9444\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 3.3775 - auc: 0.6779 - acc: 0.6667 - entropy: 1.0486 - val_loss: 1.0128 - val_auc: 0.8492 - val_acc: 0.8182 - val_entropy: 1.0128\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 3.3322 - auc: 0.6765 - acc: 0.5965 - entropy: 1.0769 - val_loss: 1.0387 - val_auc: 0.8518 - val_acc: 0.8182 - val_entropy: 1.0387\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 3.3130 - auc: 0.7035 - acc: 0.5965 - entropy: 1.0740 - val_loss: 1.0204 - val_auc: 0.8461 - val_acc: 0.8182 - val_entropy: 1.0204\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 3.3230 - auc: 0.7061 - acc: 0.6228 - entropy: 1.0627 - val_loss: 1.0034 - val_auc: 0.8285 - val_acc: 0.8182 - val_entropy: 1.0034\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 3.3126 - auc: 0.7299 - acc: 0.6316 - entropy: 1.0494 - val_loss: 1.0021 - val_auc: 0.8518 - val_acc: 0.8182 - val_entropy: 1.0021\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 3.3063 - auc: 0.7293 - acc: 0.6404 - entropy: 1.0501 - val_loss: 1.0091 - val_auc: 0.8388 - val_acc: 0.8182 - val_entropy: 1.0091\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 3.3055 - auc: 0.7170 - acc: 0.5965 - entropy: 1.0537 - val_loss: 1.0165 - val_auc: 0.8440 - val_acc: 0.8182 - val_entropy: 1.0165\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 3.3092 - auc: 0.6972 - acc: 0.5614 - entropy: 1.0580 - val_loss: 1.0172 - val_auc: 0.8476 - val_acc: 0.8182 - val_entropy: 1.0172\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 3.2748 - auc: 0.7256 - acc: 0.5965 - entropy: 1.0454 - val_loss: 1.0057 - val_auc: 0.8440 - val_acc: 0.8182 - val_entropy: 1.0057\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 3.2872 - auc: 0.7050 - acc: 0.5439 - entropy: 1.0452 - val_loss: 1.0135 - val_auc: 0.8388 - val_acc: 0.8182 - val_entropy: 1.0135\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 3.2903 - auc: 0.6681 - acc: 0.5000 - entropy: 1.0529 - val_loss: 1.0143 - val_auc: 0.8352 - val_acc: 0.8182 - val_entropy: 1.0143\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 3.2481 - auc: 0.7144 - acc: 0.5439 - entropy: 1.0387 - val_loss: 1.0013 - val_auc: 0.8270 - val_acc: 0.7727 - val_entropy: 1.0013\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 3.2607 - auc: 0.6850 - acc: 0.4825 - entropy: 1.0370 - val_loss: 0.9993 - val_auc: 0.7960 - val_acc: 0.6818 - val_entropy: 0.9993\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 3.2465 - auc: 0.6669 - acc: 0.4211 - entropy: 1.0374 - val_loss: 1.0061 - val_auc: 0.7717 - val_acc: 0.6364 - val_entropy: 1.0061\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 3.2253 - auc: 0.6543 - acc: 0.4123 - entropy: 1.0369 - val_loss: 1.0028 - val_auc: 0.7670 - val_acc: 0.6818 - val_entropy: 1.0028\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0028 - auc: 0.7670 - acc: 0.6818 - entropy: 1.0028\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 4.0159 - auc: 0.4318 - acc: 0.2719 - entropy: 1.5076 - val_loss: 0.6217 - val_auc: 0.8729 - val_acc: 0.8182 - val_entropy: 0.6217\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 4.3217 - auc: 0.6005 - acc: 0.4474 - entropy: 1.1385 - val_loss: 1.1992 - val_auc: 0.1622 - val_acc: 0.0909 - val_entropy: 1.1992\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 3.3318 - auc: 0.2179 - acc: 0.1491 - entropy: 1.1916 - val_loss: 1.1306 - val_auc: 0.1467 - val_acc: 0.0909 - val_entropy: 1.1306\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 3.2766 - auc: 0.6204 - acc: 0.4211 - entropy: 1.0883 - val_loss: 1.0117 - val_auc: 0.8843 - val_acc: 0.8182 - val_entropy: 1.0117\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 3.3023 - auc: 0.7732 - acc: 0.6667 - entropy: 1.0351 - val_loss: 0.9689 - val_auc: 0.8693 - val_acc: 0.8182 - val_entropy: 0.9689\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 3.3291 - auc: 0.7166 - acc: 0.6667 - entropy: 1.0310 - val_loss: 0.9855 - val_auc: 0.8554 - val_acc: 0.8182 - val_entropy: 0.9855\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 3.3142 - auc: 0.7380 - acc: 0.6667 - entropy: 1.0390 - val_loss: 0.9999 - val_auc: 0.8554 - val_acc: 0.8182 - val_entropy: 0.9999\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 3.2929 - auc: 0.7650 - acc: 0.6667 - entropy: 1.0398 - val_loss: 0.9959 - val_auc: 0.8554 - val_acc: 0.8182 - val_entropy: 0.9959\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 3.2806 - auc: 0.7660 - acc: 0.6404 - entropy: 1.0370 - val_loss: 0.9903 - val_auc: 0.8559 - val_acc: 0.8182 - val_entropy: 0.9903\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 3.2657 - auc: 0.7530 - acc: 0.5614 - entropy: 1.0279 - val_loss: 0.9789 - val_auc: 0.8435 - val_acc: 0.7727 - val_entropy: 0.9789\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 3.2253 - auc: 0.7420 - acc: 0.5439 - entropy: 1.0135 - val_loss: 0.9645 - val_auc: 0.8352 - val_acc: 0.7727 - val_entropy: 0.9645\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 3.1938 - auc: 0.7333 - acc: 0.5702 - entropy: 1.0070 - val_loss: 0.9330 - val_auc: 0.8363 - val_acc: 0.7727 - val_entropy: 0.9330\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 3.2011 - auc: 0.7084 - acc: 0.5526 - entropy: 0.9987 - val_loss: 0.9365 - val_auc: 0.7908 - val_acc: 0.6818 - val_entropy: 0.9365\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 3.2018 - auc: 0.6720 - acc: 0.5175 - entropy: 1.0072 - val_loss: 0.9590 - val_auc: 0.7660 - val_acc: 0.6818 - val_entropy: 0.9590\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 3.1292 - auc: 0.6778 - acc: 0.5439 - entropy: 1.0085 - val_loss: 0.9123 - val_auc: 0.8084 - val_acc: 0.6364 - val_entropy: 0.9123\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 3.1196 - auc: 0.7239 - acc: 0.5614 - entropy: 0.9705 - val_loss: 0.9106 - val_auc: 0.7825 - val_acc: 0.6364 - val_entropy: 0.9106\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 3.1232 - auc: 0.6945 - acc: 0.5000 - entropy: 0.9806 - val_loss: 0.9167 - val_auc: 0.7645 - val_acc: 0.5909 - val_entropy: 0.9167\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 3.0732 - auc: 0.6962 - acc: 0.5351 - entropy: 0.9880 - val_loss: 0.8616 - val_auc: 0.8125 - val_acc: 0.6818 - val_entropy: 0.8616\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 3.1297 - auc: 0.6881 - acc: 0.4825 - entropy: 0.9891 - val_loss: 0.9352 - val_auc: 0.7293 - val_acc: 0.5000 - val_entropy: 0.9352\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 3.0229 - auc: 0.7036 - acc: 0.5351 - entropy: 0.9787 - val_loss: 0.8806 - val_auc: 0.7784 - val_acc: 0.5909 - val_entropy: 0.8806\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8806 - auc: 0.7784 - acc: 0.5909 - entropy: 0.8806\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 4.2531 - auc: 0.4104 - acc: 0.2719 - entropy: 1.7482 - val_loss: 0.6048 - val_auc: 0.8626 - val_acc: 0.8182 - val_entropy: 0.6048\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 4.6276 - auc: 0.6091 - acc: 0.4474 - entropy: 1.1661 - val_loss: 1.2408 - val_auc: 0.1291 - val_acc: 0.0909 - val_entropy: 1.2408\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 3.3524 - auc: 0.2287 - acc: 0.1842 - entropy: 1.2334 - val_loss: 1.1332 - val_auc: 0.4917 - val_acc: 0.0909 - val_entropy: 1.1332\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 3.2798 - auc: 0.6196 - acc: 0.4386 - entropy: 1.0780 - val_loss: 0.9528 - val_auc: 0.8259 - val_acc: 0.8182 - val_entropy: 0.9528\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 3.3541 - auc: 0.7170 - acc: 0.6667 - entropy: 1.0181 - val_loss: 0.9560 - val_auc: 0.8337 - val_acc: 0.8182 - val_entropy: 0.9560\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 3.3570 - auc: 0.6902 - acc: 0.6667 - entropy: 1.0473 - val_loss: 1.0160 - val_auc: 0.8512 - val_acc: 0.8182 - val_entropy: 1.0160\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 3.3343 - auc: 0.6943 - acc: 0.6579 - entropy: 1.0714 - val_loss: 1.0246 - val_auc: 0.8502 - val_acc: 0.8182 - val_entropy: 1.0246\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 3.3106 - auc: 0.7313 - acc: 0.6579 - entropy: 1.0604 - val_loss: 0.9957 - val_auc: 0.8580 - val_acc: 0.8182 - val_entropy: 0.9957\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 3.3113 - auc: 0.7383 - acc: 0.6667 - entropy: 1.0501 - val_loss: 0.9975 - val_auc: 0.8605 - val_acc: 0.8182 - val_entropy: 0.9975\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 3.2838 - auc: 0.7667 - acc: 0.6316 - entropy: 1.0398 - val_loss: 0.9778 - val_auc: 0.8740 - val_acc: 0.8182 - val_entropy: 0.9778\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 3.2611 - auc: 0.7669 - acc: 0.5789 - entropy: 1.0230 - val_loss: 0.9621 - val_auc: 0.8822 - val_acc: 0.8182 - val_entropy: 0.9621\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 3.2883 - auc: 0.7099 - acc: 0.5439 - entropy: 1.0375 - val_loss: 0.9754 - val_auc: 0.8605 - val_acc: 0.7727 - val_entropy: 0.9754\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 3.2425 - auc: 0.7266 - acc: 0.5351 - entropy: 1.0268 - val_loss: 0.9648 - val_auc: 0.8538 - val_acc: 0.6818 - val_entropy: 0.9648\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 3.2212 - auc: 0.7287 - acc: 0.5439 - entropy: 1.0145 - val_loss: 0.9468 - val_auc: 0.8518 - val_acc: 0.6818 - val_entropy: 0.9468\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 3.1983 - auc: 0.7257 - acc: 0.5614 - entropy: 1.0016 - val_loss: 0.9250 - val_auc: 0.8450 - val_acc: 0.6818 - val_entropy: 0.9250\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 3.2077 - auc: 0.7032 - acc: 0.5439 - entropy: 1.0005 - val_loss: 0.9194 - val_auc: 0.8290 - val_acc: 0.6364 - val_entropy: 0.9194\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 3.1983 - auc: 0.6903 - acc: 0.5263 - entropy: 1.0068 - val_loss: 0.9286 - val_auc: 0.7991 - val_acc: 0.5909 - val_entropy: 0.9286\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 3.1890 - auc: 0.6419 - acc: 0.5263 - entropy: 1.0359 - val_loss: 0.9112 - val_auc: 0.8120 - val_acc: 0.5909 - val_entropy: 0.9112\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 3.1662 - auc: 0.6924 - acc: 0.5351 - entropy: 0.9945 - val_loss: 0.9094 - val_auc: 0.8073 - val_acc: 0.6364 - val_entropy: 0.9094\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 3.1763 - auc: 0.6887 - acc: 0.5175 - entropy: 1.0038 - val_loss: 0.9188 - val_auc: 0.7975 - val_acc: 0.5909 - val_entropy: 0.9188\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9188 - auc: 0.7975 - acc: 0.5909 - entropy: 0.9188\n",
      "auc : average=0.795, std=0.021\n",
      "acc : average=0.636, std=0.041\n",
      "entropy : average=0.922, std=0.043\n"
     ]
    }
   ],
   "source": [
    "calculate_mean_std(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d6740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
